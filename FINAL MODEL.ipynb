{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "42e61a43",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import joblib\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from datetime import datetime\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import make_pipeline, Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix\n",
    "\n",
    "from sklearn.ensemble import AdaBoostClassifier, GradientBoostingClassifier, RandomForestClassifier\n",
    "\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "%matplotlib inline\n",
    "\n",
    "import fairlearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f14ca3a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fb88cc26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>sex</th>\n",
       "      <th>dob</th>\n",
       "      <th>age</th>\n",
       "      <th>race</th>\n",
       "      <th>c_jail_in</th>\n",
       "      <th>c_jail_out</th>\n",
       "      <th>c_case_number</th>\n",
       "      <th>c_offense_date</th>\n",
       "      <th>...</th>\n",
       "      <th>r_case_number</th>\n",
       "      <th>r_offense_date</th>\n",
       "      <th>r_charge_degree</th>\n",
       "      <th>r_charge_desc</th>\n",
       "      <th>is_violent_recid</th>\n",
       "      <th>vr_case_number</th>\n",
       "      <th>vr_offense_date</th>\n",
       "      <th>vr_charge_degree</th>\n",
       "      <th>vr_charge_desc</th>\n",
       "      <th>two_year_recid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>steven lux</td>\n",
       "      <td>Male</td>\n",
       "      <td>1953-06-15</td>\n",
       "      <td>62</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>2013-01-05 04:35:31</td>\n",
       "      <td>2013-01-07 03:18:03</td>\n",
       "      <td>13000208CF10A</td>\n",
       "      <td>2013-01-05</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>andre small</td>\n",
       "      <td>Male</td>\n",
       "      <td>1987-10-01</td>\n",
       "      <td>28</td>\n",
       "      <td>African-American</td>\n",
       "      <td>2013-04-02 12:18:46</td>\n",
       "      <td>2013-04-04 07:54:22</td>\n",
       "      <td>13006354MM10A</td>\n",
       "      <td>2013-04-02</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>willie gray</td>\n",
       "      <td>Male</td>\n",
       "      <td>1959-01-12</td>\n",
       "      <td>57</td>\n",
       "      <td>African-American</td>\n",
       "      <td>2014-10-31 12:02:01</td>\n",
       "      <td>2014-10-31 01:47:05</td>\n",
       "      <td>14040148MU10A</td>\n",
       "      <td>2014-10-30</td>\n",
       "      <td>...</td>\n",
       "      <td>15043364TC20A</td>\n",
       "      <td>2015-07-23</td>\n",
       "      <td>(M2)</td>\n",
       "      <td>Driving License Suspended</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>nickson marcellus</td>\n",
       "      <td>Male</td>\n",
       "      <td>1996-07-11</td>\n",
       "      <td>19</td>\n",
       "      <td>African-American</td>\n",
       "      <td>2014-01-23 03:19:30</td>\n",
       "      <td>2014-01-23 01:04:34</td>\n",
       "      <td>13017969CF10A</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>16000241MM20A</td>\n",
       "      <td>2016-01-04</td>\n",
       "      <td>(M1)</td>\n",
       "      <td>Possess Cannabis/20 Grams Or Less</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>patria barnes</td>\n",
       "      <td>Female</td>\n",
       "      <td>1978-06-06</td>\n",
       "      <td>37</td>\n",
       "      <td>Other</td>\n",
       "      <td>2013-12-08 01:55:28</td>\n",
       "      <td>2013-12-09 02:00:59</td>\n",
       "      <td>13022717MM10A</td>\n",
       "      <td>2013-12-07</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6109</th>\n",
       "      <td>6110</td>\n",
       "      <td>seccunda davis</td>\n",
       "      <td>Male</td>\n",
       "      <td>1987-05-13</td>\n",
       "      <td>28</td>\n",
       "      <td>African-American</td>\n",
       "      <td>2013-08-18 07:25:24</td>\n",
       "      <td>2013-08-19 09:01:42</td>\n",
       "      <td>13015644MM10A</td>\n",
       "      <td>2013-08-18</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6110</th>\n",
       "      <td>6111</td>\n",
       "      <td>mark montgomery</td>\n",
       "      <td>Male</td>\n",
       "      <td>1985-11-03</td>\n",
       "      <td>30</td>\n",
       "      <td>African-American</td>\n",
       "      <td>2013-03-23 01:32:34</td>\n",
       "      <td>2013-03-28 09:37:27</td>\n",
       "      <td>13005696MM10A</td>\n",
       "      <td>2013-03-23</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6111</th>\n",
       "      <td>6112</td>\n",
       "      <td>erica johnson</td>\n",
       "      <td>Female</td>\n",
       "      <td>1982-06-23</td>\n",
       "      <td>33</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>2013-09-29 09:25:30</td>\n",
       "      <td>2013-09-30 09:59:37</td>\n",
       "      <td>13013661CF10A</td>\n",
       "      <td>2013-09-29</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6112</th>\n",
       "      <td>6113</td>\n",
       "      <td>barry williams</td>\n",
       "      <td>Male</td>\n",
       "      <td>1988-04-22</td>\n",
       "      <td>27</td>\n",
       "      <td>African-American</td>\n",
       "      <td>2013-10-30 03:40:14</td>\n",
       "      <td>2013-12-07 01:53:45</td>\n",
       "      <td>13004112MM10A</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6113</th>\n",
       "      <td>6114</td>\n",
       "      <td>travis joseph</td>\n",
       "      <td>Male</td>\n",
       "      <td>1991-05-25</td>\n",
       "      <td>24</td>\n",
       "      <td>African-American</td>\n",
       "      <td>2013-01-08 01:30:33</td>\n",
       "      <td>2013-01-09 12:44:02</td>\n",
       "      <td>12013129CF10A</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>14006980MM10A</td>\n",
       "      <td>2014-04-27</td>\n",
       "      <td>(M2)</td>\n",
       "      <td>Petit Theft</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6114 rows Ã— 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id               name     sex         dob  age              race  \\\n",
       "0        1         steven lux    Male  1953-06-15   62         Caucasian   \n",
       "1        2        andre small    Male  1987-10-01   28  African-American   \n",
       "2        3        willie gray    Male  1959-01-12   57  African-American   \n",
       "3        4  nickson marcellus    Male  1996-07-11   19  African-American   \n",
       "4        5      patria barnes  Female  1978-06-06   37             Other   \n",
       "...    ...                ...     ...         ...  ...               ...   \n",
       "6109  6110     seccunda davis    Male  1987-05-13   28  African-American   \n",
       "6110  6111    mark montgomery    Male  1985-11-03   30  African-American   \n",
       "6111  6112      erica johnson  Female  1982-06-23   33         Caucasian   \n",
       "6112  6113     barry williams    Male  1988-04-22   27  African-American   \n",
       "6113  6114      travis joseph    Male  1991-05-25   24  African-American   \n",
       "\n",
       "                c_jail_in           c_jail_out  c_case_number c_offense_date  \\\n",
       "0     2013-01-05 04:35:31  2013-01-07 03:18:03  13000208CF10A     2013-01-05   \n",
       "1     2013-04-02 12:18:46  2013-04-04 07:54:22  13006354MM10A     2013-04-02   \n",
       "2     2014-10-31 12:02:01  2014-10-31 01:47:05  14040148MU10A     2014-10-30   \n",
       "3     2014-01-23 03:19:30  2014-01-23 01:04:34  13017969CF10A            NaN   \n",
       "4     2013-12-08 01:55:28  2013-12-09 02:00:59  13022717MM10A     2013-12-07   \n",
       "...                   ...                  ...            ...            ...   \n",
       "6109  2013-08-18 07:25:24  2013-08-19 09:01:42  13015644MM10A     2013-08-18   \n",
       "6110  2013-03-23 01:32:34  2013-03-28 09:37:27  13005696MM10A     2013-03-23   \n",
       "6111  2013-09-29 09:25:30  2013-09-30 09:59:37  13013661CF10A     2013-09-29   \n",
       "6112  2013-10-30 03:40:14  2013-12-07 01:53:45  13004112MM10A            NaN   \n",
       "6113  2013-01-08 01:30:33  2013-01-09 12:44:02  12013129CF10A            NaN   \n",
       "\n",
       "      ...  r_case_number r_offense_date r_charge_degree  \\\n",
       "0     ...            NaN            NaN             NaN   \n",
       "1     ...            NaN            NaN             NaN   \n",
       "2     ...  15043364TC20A     2015-07-23            (M2)   \n",
       "3     ...  16000241MM20A     2016-01-04            (M1)   \n",
       "4     ...            NaN            NaN             NaN   \n",
       "...   ...            ...            ...             ...   \n",
       "6109  ...            NaN            NaN             NaN   \n",
       "6110  ...            NaN            NaN             NaN   \n",
       "6111  ...            NaN            NaN             NaN   \n",
       "6112  ...            NaN            NaN             NaN   \n",
       "6113  ...  14006980MM10A     2014-04-27            (M2)   \n",
       "\n",
       "                          r_charge_desc  is_violent_recid  vr_case_number  \\\n",
       "0                                   NaN                 0             NaN   \n",
       "1                                   NaN                 0             NaN   \n",
       "2             Driving License Suspended                 0             NaN   \n",
       "3     Possess Cannabis/20 Grams Or Less                 0             NaN   \n",
       "4                                   NaN                 0             NaN   \n",
       "...                                 ...               ...             ...   \n",
       "6109                                NaN                 0             NaN   \n",
       "6110                                NaN                 0             NaN   \n",
       "6111                                NaN                 0             NaN   \n",
       "6112                                NaN                 0             NaN   \n",
       "6113                        Petit Theft                 0             NaN   \n",
       "\n",
       "      vr_offense_date vr_charge_degree vr_charge_desc  two_year_recid  \n",
       "0                 NaN              NaN            NaN               0  \n",
       "1                 NaN              NaN            NaN               0  \n",
       "2                 NaN              NaN            NaN               1  \n",
       "3                 NaN              NaN            NaN               1  \n",
       "4                 NaN              NaN            NaN               0  \n",
       "...               ...              ...            ...             ...  \n",
       "6109              NaN              NaN            NaN               0  \n",
       "6110              NaN              NaN            NaN               0  \n",
       "6111              NaN              NaN            NaN               0  \n",
       "6112              NaN              NaN            NaN               0  \n",
       "6113              NaN              NaN            NaN               1  \n",
       "\n",
       "[6114 rows x 35 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv('two-years-recid.csv')#.set_index('id')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0b1718e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "## REMOVING ROWS FOR GOAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7329dde4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3513/2141686846.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['c_jail_in'] = pd.to_datetime(df['c_jail_in'])\n",
      "/tmp/ipykernel_3513/2141686846.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['c_jail_out'] = pd.to_datetime(df['c_jail_out'])\n",
      "/tmp/ipykernel_3513/2141686846.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['r_offense_date'] = pd.to_datetime(df['r_offense_date'])\n",
      "/tmp/ipykernel_3513/2141686846.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['offense_jail_duration'] = (df['r_offense_date'] - df['c_jail_out']).dt.days\n",
      "/tmp/ipykernel_3513/2141686846.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['two_year_recid'] = ((df['is_recid'] == 1) & (df['offense_jail_duration'] <= 365 * 2)).astype(int)\n",
      "/tmp/ipykernel_3513/2141686846.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['is_recid']=df['two_year_recid']\n"
     ]
    }
   ],
   "source": [
    "df = df.dropna(subset=['c_jail_out'])\n",
    "\n",
    "# Suppose df_test has some different values, so we'll modify it directly\n",
    "# Convert columns to datetime if they are not already\n",
    "df['c_jail_in'] = pd.to_datetime(df['c_jail_in'])\n",
    "df['c_jail_out'] = pd.to_datetime(df['c_jail_out'])\n",
    "\n",
    "df['r_offense_date'] = pd.to_datetime(df['r_offense_date'])\n",
    "\n",
    "\n",
    "# Calculate the difference between 'r_offense_date' and 'c_jail_out'\n",
    "df['offense_jail_duration'] = (df['r_offense_date'] - df['c_jail_out']).dt.days\n",
    "\n",
    "# Create a new column based on your conditions\n",
    "df['two_year_recid'] = ((df['is_recid'] == 1) & (df['offense_jail_duration'] <= 365 * 2)).astype(int)\n",
    "\n",
    "#\n",
    "df['is_recid']=df['two_year_recid']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "055da465",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                       5854\n",
       "name                     5854\n",
       "sex                      5854\n",
       "dob                      5854\n",
       "age                      5854\n",
       "race                     5854\n",
       "c_jail_in                5854\n",
       "c_jail_out               5854\n",
       "c_case_number            5854\n",
       "c_offense_date           4983\n",
       "c_arrest_date             871\n",
       "c_charge_degree          5854\n",
       "c_charge_desc            5848\n",
       "juv_fel_count            5854\n",
       "juv_misd_count           5854\n",
       "juv_other_count          5854\n",
       "priors_count             5854\n",
       "compas_screening_date    5854\n",
       "type_of_assessment       5854\n",
       "decile_score             5854\n",
       "score_text               5854\n",
       "v_type_of_assessment     5854\n",
       "v_decile_score           5854\n",
       "v_score_text             5854\n",
       "is_recid                 5854\n",
       "r_case_number            2879\n",
       "r_offense_date           2879\n",
       "r_charge_degree          2879\n",
       "r_charge_desc            2830\n",
       "is_violent_recid         5854\n",
       "vr_case_number            681\n",
       "vr_offense_date           681\n",
       "vr_charge_degree          681\n",
       "vr_charge_desc            681\n",
       "two_year_recid           5854\n",
       "offense_jail_duration    2879\n",
       "dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "70f57b53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Swap c_jail_in and c_jail_out where c_jail_out is before c_jail_in and the difference is less than one day\n",
    "swap_mask = (df['c_jail_out'] < df['c_jail_in']) & ((df['c_jail_in'] - df['c_jail_out']).dt.days < 1)\n",
    "df.loc[swap_mask, ['c_jail_in', 'c_jail_out']] = df.loc[swap_mask, ['c_jail_out', 'c_jail_in']].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5fef729b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3513/2362044094.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['invalid_jail_in_arrest'] = df['c_jail_in'] < df['c_arrest_date']\n",
      "/tmp/ipykernel_3513/2362044094.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['invalid_jail_in_offense'] = df['c_jail_in'] < df['c_offense_date']\n"
     ]
    }
   ],
   "source": [
    "#non sense rows\n",
    "df['invalid_jail_in_arrest'] = df['c_jail_in'] < df['c_arrest_date']\n",
    "df['invalid_jail_in_offense'] = df['c_jail_in'] < df['c_offense_date']\n",
    "\n",
    "# Remove rows where both conditions are true\n",
    "df = df[~(df['invalid_jail_in_arrest'] & df['invalid_jail_in_offense'])]\n",
    "\n",
    "# Drop the columns after filtering\n",
    "df = df.drop(columns=['invalid_jail_in_arrest', 'invalid_jail_in_offense'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "db8df348",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['c_jail_in'] >= '2012-01-01']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "9361278a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.69\n",
      "Precision: 0.68\n",
      "Recall: 0.60\n",
      "F1-Score: 0.64\n",
      "ROC-AUC: 0.74\n",
      "Confusion Matrix:\n",
      "[[495 149]\n",
      " [211 316]]\n",
      "\n",
      "Fairness metrics for sex:\n",
      "Disparate Impact Ratio: 0.55\n",
      "Equalized Odds Ratio: 0.45\n",
      "True Positive Rate Difference: 0.15\n",
      "False Positive Rate Difference: 0.15\n",
      "Selection Rate Difference: 0.19\n",
      "\n",
      "Fairness metrics for race:\n",
      "Disparate Impact Ratio: 0.22\n",
      "Equalized Odds Ratio: 0.00\n",
      "True Positive Rate Difference: 1.00\n",
      "False Positive Rate Difference: 0.30\n",
      "Selection Rate Difference: 0.58\n",
      "\n",
      "Fairness metrics for age_group:\n",
      "Disparate Impact Ratio: 0.00\n",
      "Equalized Odds Ratio: 0.00\n",
      "True Positive Rate Difference: 0.68\n",
      "False Positive Rate Difference: 0.41\n",
      "Selection Rate Difference: 0.56\n",
      "\n",
      "Fairness metrics for priors_count_bin:\n",
      "Disparate Impact Ratio: 0.07\n",
      "Equalized Odds Ratio: 0.04\n",
      "True Positive Rate Difference: 0.85\n",
      "False Positive Rate Difference: 0.96\n",
      "Selection Rate Difference: 0.93\n",
      "\n",
      "Disparate Impact Ratios by Sex:\n",
      "Male: 1.10\n",
      "Female: 0.61\n",
      "\n",
      "Disparate Impact Ratios by Race:\n",
      "African-American: 1.26\n",
      "Asian: 0.42\n",
      "Caucasian: 0.70\n",
      "Other: 0.82\n",
      "Hispanic: 0.75\n",
      "Native American: 1.89\n",
      "\n",
      "Disparate Impact Ratios by Age_group:\n",
      "36-45: 1.16\n",
      "26-35: 1.40\n",
      "56-65: 0.49\n",
      "46-55: 0.55\n",
      "66+: 0.67\n",
      "missing_value: 0.00\n",
      "\n",
      "Disparate Impact Ratios by Priors_count_bin:\n",
      "10+: 2.50\n",
      "3-4: 1.61\n",
      "0: 0.16\n",
      "1-2: 0.59\n",
      "5-9: 1.89\n"
     ]
    }
   ],
   "source": [
    "##FIL IN AVG\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, FunctionTransformer\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "#from xgboost import XGBClassifier\n",
    "import joblib\n",
    "\n",
    "# Define the categorize_charge function\n",
    "# Frequency encoding\n",
    "def frequency_encoding(df, column):\n",
    "    freq_encoding = df[column].value_counts(normalize=True)\n",
    "    df[f'{column}_freq'] = df[column].map(freq_encoding)\n",
    "    return df\n",
    "\n",
    "# Define the preprocess_data function\n",
    "def preprocess_data(df):\n",
    "    \n",
    "    df['dob'] = pd.to_datetime(df['dob'])\n",
    "    df['c_offense_date'] = pd.to_datetime(df['c_offense_date'])\n",
    "    df['c_arrest_date'] = pd.to_datetime(df['c_arrest_date'])\n",
    "    df['c_jail_in'] = pd.to_datetime(df['c_jail_in'])\n",
    "\n",
    "    # Create unified_date\n",
    "    df['unified_date'] = df['c_arrest_date'].combine_first(df['c_offense_date'])\n",
    "\n",
    "    # Feature engineering\n",
    "    df['age_birth'] = (pd.to_datetime('today') - df['dob']).dt.days // 365\n",
    "    df['age_at_unified_date'] = (df['unified_date'] - df['dob']).dt.days // 365\n",
    "    \n",
    "    # Calculate averages for filling NaN values\n",
    "    avg_time_offense_arrest = (df['c_arrest_date'] - df['c_offense_date']).dt.days.mean()\n",
    "    avg_time_since_jail_in = (pd.to_datetime('today') - df['c_jail_in']).dt.days.mean()\n",
    "    avg_time_to_jail = (df['c_jail_in'] - df['unified_date']).dt.days.mean()\n",
    "\n",
    "    df['time_offense_arrest'] = (df['c_arrest_date'] - df['c_offense_date']).dt.days.fillna(avg_time_offense_arrest)  # Fill NaN with average\n",
    "    df['time_since_jail_in'] = (pd.to_datetime('today') - df['c_jail_in']).dt.days.fillna(avg_time_since_jail_in)  # Duration in jail till today\n",
    "    df['time_to_jail'] = (df['c_jail_in'] - df['unified_date']).dt.days.fillna(avg_time_to_jail)\n",
    "    \n",
    "    df['total_juv_crimes'] = df['juv_fel_count'] + df['juv_misd_count'] + df['juv_other_count']\n",
    "    df['total_adult_crimes'] = df['priors_count'] - df['total_juv_crimes']\n",
    "\n",
    "    \n",
    "    bins = [0, 1, 3, 5, 10, np.inf]\n",
    "    labels = ['0', '1-2', '3-4', '5-9', '10+']\n",
    "    df['priors_count_bin'] = pd.cut(df['priors_count'], bins=bins, labels=labels, right=False)\n",
    "\n",
    "    \n",
    "    # Apply frequency encoding and group less frequent categories\n",
    "    df = frequency_encoding(df, 'c_charge_desc')\n",
    "\n",
    "    # Create age bins and handle missing values\n",
    "    bins = [18, 25, 35, 45, 55, 65, 100]\n",
    "    labels = ['18-25', '26-35', '36-45', '46-55', '56-65', '66+']\n",
    "    df['age_group'] = pd.cut(df['age_birth'], bins=bins, labels=labels, right=False)\n",
    "    df['age_group'] = df['age_group'].cat.add_categories('missing_value').fillna('missing_value')\n",
    "    \n",
    "    # Extract more granular date features\n",
    "    df['offense_month'] = df['c_offense_date'].dt.month.fillna(df['c_offense_date'].dt.month.mean())\n",
    "    df['offense_day_of_week'] = df['c_offense_date'].dt.dayofweek.fillna(df['c_offense_date'].dt.dayofweek.mean())\n",
    "    df['arrest_month'] = df['c_arrest_date'].dt.month.fillna(df['c_arrest_date'].dt.month.mean())\n",
    "    df['arrest_day_of_week'] = df['c_arrest_date'].dt.dayofweek.fillna(df['c_arrest_date'].dt.dayofweek.mean())\n",
    "    df['sex_race_interaction'] = df['sex'] + '_' + df['race']\n",
    "    return df\n",
    "\n",
    "# Load data (ensure df is loaded before this step)\n",
    "# df = pd.read_csv('your_data.csv')  # Example loading method\n",
    "\n",
    "# Apply preprocessing to the entire dataset\n",
    "df = preprocess_data(df)\n",
    "\n",
    "# Split data into train and test sets\n",
    "df_train, df_test = train_test_split(df, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define features\n",
    "all_features = [\n",
    "    \"sex\", \n",
    "    \"race\", \n",
    "    #\"juv_fel_count\", \n",
    "    #\"juv_misd_count\", \n",
    "    #\"juv_other_count\",\n",
    "    \"total_adult_crimes\", \n",
    "    \"c_charge_degree\", \n",
    "   # \"c_charge_desc\", \n",
    "    \"c_charge_desc_freq\",\n",
    "    \"age_at_unified_date\", \n",
    "    \"total_juv_crimes\",\n",
    "    \"offense_month\", \n",
    "    \"offense_day_of_week\", \n",
    "    \"arrest_month\", \n",
    "    \"arrest_day_of_week\",\n",
    "    \"age_group\",\n",
    "    \"priors_count_bin\"\n",
    "]\n",
    "\n",
    "numerical_features = [\n",
    "   # \"juv_fel_count\", \n",
    "    #\"juv_misd_count\", \n",
    "    #\"juv_other_count\", \n",
    "    \"total_adult_crimes\",\n",
    "    #\"time_offense_arrest\", \n",
    "    #\"time_since_jail_in\", \n",
    "    \"total_juv_crimes\",\n",
    "    \"offense_month\", \n",
    "    \"offense_day_of_week\", \n",
    "    \"arrest_month\", \n",
    "    \"arrest_day_of_week\",\n",
    "    \"age_at_unified_date\", \n",
    "    #\"age_birth\",\n",
    "    \"c_charge_desc_freq\",\n",
    "    #\"priors_count\"\n",
    "]\n",
    "\n",
    "categorical_features = [\n",
    "    \"sex\", \n",
    "    \"race\", \n",
    "    \"c_charge_degree\", \n",
    "   # \"c_charge_desc\",\n",
    "    \"age_group\",\n",
    "    \"priors_count_bin\",\n",
    "]\n",
    "\n",
    "target = 'is_recid'\n",
    "\n",
    "# Define preprocessing pipelines\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value='missing_value')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numerical_features),\n",
    "        ('cat', categorical_transformer, categorical_features)\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Use the best model parameters found earlier\n",
    "best_model_params = {\n",
    "    'learning_rate': 0.01,\n",
    "    'max_depth': 3,\n",
    "    'n_estimators': 300,\n",
    "    'subsample': 0.8,\n",
    "    'random_state': 42\n",
    "}\n",
    "\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', GradientBoostingClassifier(**best_model_params))\n",
    "])\n",
    "\n",
    "\n",
    "# Train the updated pipeline\n",
    "X_train = df_train[all_features]\n",
    "y_train = df_train[target]\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the updated pipeline on the test set\n",
    "X_test = df_test[all_features]\n",
    "y_test = df_test[target]\n",
    "y_pred = pipeline.predict(X_test)\n",
    "y_proba = pipeline.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "roc_auc = roc_auc_score(y_test, y_proba)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Print evaluation metrics\n",
    "print(f'Accuracy: {accuracy:.2f}')\n",
    "print(f'Precision: {precision:.2f}')\n",
    "print(f'Recall: {recall:.2f}')\n",
    "print(f'F1-Score: {f1:.2f}')\n",
    "print(f'ROC-AUC: {roc_auc:.2f}')\n",
    "print(f'Confusion Matrix:\\n{conf_matrix}')\n",
    "\n",
    "#####FAIRNESS#######\n",
    "# Fairness and Bias Metrics\n",
    "from fairlearn.metrics import (\n",
    "    demographic_parity_ratio,\n",
    "    equalized_odds_ratio,\n",
    "    true_positive_rate_difference,\n",
    "    false_positive_rate_difference,\n",
    "    selection_rate_difference\n",
    ")\n",
    "import numpy as np\n",
    "\n",
    "# Function to calculate fairness metrics for a given feature\n",
    "\n",
    "# Fairness metrics\n",
    "for feature in ['sex', 'race', 'age_group','priors_count_bin']:\n",
    "    print(f\"\\nFairness metrics for {feature}:\")\n",
    "    disparate_impact = demographic_parity_ratio(y_true=y_test, y_pred=y_pred, sensitive_features=X_test[feature])\n",
    "    equalized_odds = equalized_odds_ratio(y_true=y_test, y_pred=y_pred, sensitive_features=X_test[feature])\n",
    "    tpr_diff = true_positive_rate_difference(y_true=y_test, y_pred=y_pred, sensitive_features=X_test[feature])\n",
    "    fpr_diff = false_positive_rate_difference(y_true=y_test, y_pred=y_pred, sensitive_features=X_test[feature])\n",
    "    selection_rate_diff = selection_rate_difference(y_true=y_test, y_pred=y_pred, sensitive_features=X_test[feature])\n",
    "    print(f\"Disparate Impact Ratio: {disparate_impact:.2f}\")\n",
    "    print(f\"Equalized Odds Ratio: {equalized_odds:.2f}\")\n",
    "    print(f\"True Positive Rate Difference: {tpr_diff:.2f}\")\n",
    "    print(f\"False Positive Rate Difference: {fpr_diff:.2f}\")\n",
    "    print(f\"Selection Rate Difference: {selection_rate_diff:.2f}\")\n",
    "\n",
    "# Disparate impact ratios by group for each sensitive feature\n",
    "def calculate_disparate_impact(y_true, y_pred, X_test, column):\n",
    "    disparate_impact_ratios = {}\n",
    "    overall_favorable_outcomes = y_pred.mean()\n",
    "    for value in X_test[column].unique():\n",
    "        mask = X_test[column] == value\n",
    "        favorable_outcomes = y_pred[mask].mean()\n",
    "        if overall_favorable_outcomes == 0:\n",
    "            disparate_impact_ratios[value] = np.nan\n",
    "        else:\n",
    "            disparate_impact_ratios[value] = favorable_outcomes / overall_favorable_outcomes\n",
    "    return disparate_impact_ratios\n",
    "\n",
    "for feature in ['sex', 'race', 'age_group', 'priors_count_bin']:\n",
    "    disparate_impact_by_group = calculate_disparate_impact(y_test, y_pred, X_test, feature)\n",
    "    print(f\"\\nDisparate Impact Ratios by {feature.capitalize()}:\")\n",
    "    for group, ratio in disparate_impact_by_group.items():\n",
    "        print(f\"{group}: {ratio:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "08d6f336",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fairness Metrics:\n",
      "         Feature  Disparate Impact Ratio  Equalized Odds Ratio  TPR Difference  FPR Difference  Selection Rate Difference\n",
      "             sex                    0.55                  0.45            0.15            0.15                       0.19\n",
      "            race                    0.22                  0.00            1.00            0.30                       0.58\n",
      "       age_group                    0.00                  0.00            0.68            0.41                       0.56\n",
      "priors_count_bin                    0.07                  0.04            0.85            0.96                       0.93\n",
      "\n",
      "Disparate Impact Ratios by Group:\n",
      "         Feature            Group  Disparate Impact Ratio\n",
      "             sex             Male                    1.10\n",
      "             sex           Female                    0.61\n",
      "            race African-American                    1.26\n",
      "            race            Asian                    0.42\n",
      "            race        Caucasian                    0.70\n",
      "            race            Other                    0.82\n",
      "            race         Hispanic                    0.75\n",
      "            race  Native American                    1.89\n",
      "       age_group            36-45                    1.16\n",
      "       age_group            26-35                    1.40\n",
      "       age_group            56-65                    0.49\n",
      "       age_group            46-55                    0.55\n",
      "       age_group              66+                    0.67\n",
      "       age_group    missing_value                    0.00\n",
      "priors_count_bin              10+                    2.50\n",
      "priors_count_bin              3-4                    1.61\n",
      "priors_count_bin                0                    0.16\n",
      "priors_count_bin              1-2                    0.59\n",
      "priors_count_bin              5-9                    1.89\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from fairlearn.metrics import (\n",
    "    demographic_parity_ratio, equalized_odds_ratio,\n",
    "    true_positive_rate_difference, false_positive_rate_difference,\n",
    "    selection_rate_difference\n",
    ")\n",
    "\n",
    "# Function to calculate fairness metrics for a given feature\n",
    "def calculate_fairness_metrics(y_test, y_pred, X_test, feature):\n",
    "    metrics = {\n",
    "        'Feature': feature,\n",
    "        'Disparate Impact Ratio': demographic_parity_ratio(y_true=y_test, y_pred=y_pred, sensitive_features=X_test[feature]),\n",
    "        'Equalized Odds Ratio': equalized_odds_ratio(y_true=y_test, y_pred=y_pred, sensitive_features=X_test[feature]),\n",
    "        'TPR Difference': true_positive_rate_difference(y_true=y_test, y_pred=y_pred, sensitive_features=X_test[feature]),\n",
    "        'FPR Difference': false_positive_rate_difference(y_true=y_test, y_pred=y_pred, sensitive_features=X_test[feature]),\n",
    "        'Selection Rate Difference': selection_rate_difference(y_true=y_test, y_pred=y_pred, sensitive_features=X_test[feature])\n",
    "    }\n",
    "    return metrics\n",
    "\n",
    "# Function to calculate disparate impact ratios by group for each sensitive feature\n",
    "def calculate_disparate_impact(y_true, y_pred, X_test, column):\n",
    "    disparate_impact_ratios = {}\n",
    "    overall_favorable_outcomes = y_pred.mean()\n",
    "    for value in X_test[column].unique():\n",
    "        mask = X_test[column] == value\n",
    "        favorable_outcomes = y_pred[mask].mean()\n",
    "        if overall_favorable_outcomes == 0:\n",
    "            disparate_impact_ratios[value] = np.nan\n",
    "        else:\n",
    "            disparate_impact_ratios[value] = favorable_outcomes / overall_favorable_outcomes\n",
    "    return disparate_impact_ratios\n",
    "\n",
    "# Create lists to store fairness metrics and disparate impact ratios\n",
    "fairness_metrics_list = []\n",
    "disparate_impact_list = []\n",
    "\n",
    "# Calculate fairness metrics for each feature\n",
    "features_to_check = ['sex', 'race', 'age_group', 'priors_count_bin']\n",
    "for feature in features_to_check:\n",
    "    metrics = calculate_fairness_metrics(y_test, y_pred, X_test, feature)\n",
    "    fairness_metrics_list.append(metrics)\n",
    "\n",
    "    # Calculate and store disparate impact ratios by group\n",
    "    disparate_impact_by_group = calculate_disparate_impact(y_test, y_pred, X_test, feature)\n",
    "    for group, ratio in disparate_impact_by_group.items():\n",
    "        disparate_impact_list.append({'Feature': feature, 'Group': group, 'Disparate Impact Ratio': ratio})\n",
    "\n",
    "# Convert lists to DataFrames\n",
    "fairness_metrics_df = pd.DataFrame(fairness_metrics_list)\n",
    "disparate_impact_df = pd.DataFrame(disparate_impact_list)\n",
    "\n",
    "# Reorder columns to have 'Feature' as the first column\n",
    "fairness_metrics_df = fairness_metrics_df[['Feature', 'Disparate Impact Ratio', 'Equalized Odds Ratio', 'TPR Difference', 'FPR Difference', 'Selection Rate Difference']]\n",
    "disparate_impact_df = disparate_impact_df[['Feature', 'Group', 'Disparate Impact Ratio']]\n",
    "\n",
    "# Format and print the DataFrames\n",
    "print(\"Fairness Metrics:\")\n",
    "print(fairness_metrics_df.round(2).to_string(index=False))\n",
    "\n",
    "print(\"\\nDisparate Impact Ratios by Group:\")\n",
    "print(disparate_impact_df.round(2).to_string(index=False))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "259abd4d",
   "metadata": {},
   "source": [
    "## SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "f0535464",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.67\n",
      "Precision: 0.63\n",
      "Recall: 0.65\n",
      "F1-Score: 0.64\n",
      "ROC-AUC: 0.74\n",
      "Confusion Matrix:\n",
      "[[444 200]\n",
      " [182 345]]\n",
      "Fairness Metrics:\n",
      "         Feature  Disparate Impact Ratio  Equalized Odds Ratio  TPR Difference  FPR Difference  Selection Rate Difference\n",
      "             sex                    0.55                  0.48            0.19            0.19                       0.23\n",
      "            race                    0.22                  0.00            1.00            0.43                       0.58\n",
      "       age_group                    0.00                  0.00            0.77            0.53                       0.66\n",
      "priors_count_bin                    0.13                  0.07            0.71            0.93                       0.86\n",
      "\n",
      "Disparate Impact Ratios by Group:\n",
      "         Feature            Group  Disparate Impact Ratio\n",
      "             sex             Male                    1.10\n",
      "             sex           Female                    0.61\n",
      "            race African-American                    1.28\n",
      "            race            Asian                    0.36\n",
      "            race        Caucasian                    0.70\n",
      "            race            Other                    0.74\n",
      "            race         Hispanic                    0.70\n",
      "            race  Native American                    1.61\n",
      "       age_group            36-45                    1.15\n",
      "       age_group            26-35                    1.43\n",
      "       age_group            56-65                    0.48\n",
      "       age_group            46-55                    0.54\n",
      "       age_group              66+                    0.64\n",
      "       age_group    missing_value                    0.00\n",
      "priors_count_bin              10+                    2.13\n",
      "priors_count_bin              3-4                    1.46\n",
      "priors_count_bin                0                    0.28\n",
      "priors_count_bin              1-2                    0.72\n",
      "priors_count_bin              5-9                    1.80\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, FunctionTransformer\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "#from xgboost import XGBClassifier\n",
    "import joblib\n",
    "\n",
    "# Define the categorize_charge function\n",
    "# Frequency encoding\n",
    "def frequency_encoding(df, column):\n",
    "    freq_encoding = df[column].value_counts(normalize=True)\n",
    "    df[f'{column}_freq'] = df[column].map(freq_encoding)\n",
    "    return df\n",
    "\n",
    "# Define the preprocess_data function\n",
    "def preprocess_data(df):\n",
    "    \n",
    "    df['dob'] = pd.to_datetime(df['dob'])\n",
    "    df['c_offense_date'] = pd.to_datetime(df['c_offense_date'])\n",
    "    df['c_arrest_date'] = pd.to_datetime(df['c_arrest_date'])\n",
    "    df['c_jail_in'] = pd.to_datetime(df['c_jail_in'])\n",
    "\n",
    "    # Create unified_date\n",
    "    df['unified_date'] = df['c_arrest_date'].combine_first(df['c_offense_date'])\n",
    "\n",
    "    # Feature engineering\n",
    "    df['age_birth'] = (pd.to_datetime('today') - df['dob']).dt.days // 365\n",
    "    df['age_at_unified_date'] = (df['unified_date'] - df['dob']).dt.days // 365\n",
    "    \n",
    "    # Calculate averages for filling NaN values\n",
    "    avg_time_offense_arrest = (df['c_arrest_date'] - df['c_offense_date']).dt.days.mean()\n",
    "    avg_time_since_jail_in = (pd.to_datetime('today') - df['c_jail_in']).dt.days.mean()\n",
    "    avg_time_to_jail = (df['c_jail_in'] - df['unified_date']).dt.days.mean()\n",
    "\n",
    "    df['time_offense_arrest'] = (df['c_arrest_date'] - df['c_offense_date']).dt.days.fillna(avg_time_offense_arrest)  # Fill NaN with average\n",
    "    df['time_since_jail_in'] = (pd.to_datetime('today') - df['c_jail_in']).dt.days.fillna(avg_time_since_jail_in)  # Duration in jail till today\n",
    "    df['time_to_jail'] = (df['c_jail_in'] - df['unified_date']).dt.days.fillna(avg_time_to_jail)\n",
    "    \n",
    "    df['total_juv_crimes'] = df['juv_fel_count'] + df['juv_misd_count'] + df['juv_other_count']\n",
    "    df['total_adult_crimes'] = df['priors_count'] - df['total_juv_crimes']\n",
    "\n",
    "    \n",
    "    bins = [0, 1, 3, 5, 10, np.inf]\n",
    "    labels = ['0', '1-2', '3-4', '5-9', '10+']\n",
    "    df['priors_count_bin'] = pd.cut(df['priors_count'], bins=bins, labels=labels, right=False)\n",
    "\n",
    "    \n",
    "    # Apply frequency encoding and group less frequent categories\n",
    "    df = frequency_encoding(df, 'c_charge_desc')\n",
    "\n",
    "    # Create age bins and handle missing values\n",
    "    bins = [18, 25, 35, 45, 55, 65, 100]\n",
    "    labels = ['18-25', '26-35', '36-45', '46-55', '56-65', '66+']\n",
    "    df['age_group'] = pd.cut(df['age_birth'], bins=bins, labels=labels, right=False)\n",
    "    df['age_group'] = df['age_group'].cat.add_categories('missing_value').fillna('missing_value')\n",
    "    \n",
    "    # Extract more granular date features\n",
    "    df['offense_month'] = df['c_offense_date'].dt.month.fillna(df['c_offense_date'].dt.month.mean())\n",
    "    df['offense_day_of_week'] = df['c_offense_date'].dt.dayofweek.fillna(df['c_offense_date'].dt.dayofweek.mean())\n",
    "    df['arrest_month'] = df['c_arrest_date'].dt.month.fillna(df['c_arrest_date'].dt.month.mean())\n",
    "    df['arrest_day_of_week'] = df['c_arrest_date'].dt.dayofweek.fillna(df['c_arrest_date'].dt.dayofweek.mean())\n",
    "    df['sex_race_interaction'] = df['sex'] + '_' + df['race']\n",
    "    \n",
    "    # Binning total_adult_crimes\n",
    "    df['total_adult_crimes'] = df['total_adult_crimes'].apply(lambda x: max(0, x)).astype(float)\n",
    "    bins = [0, 1, 3, 5, 10, np.inf]\n",
    "    labels = ['0', '1-2', '3-4', '5-9', '10+']\n",
    "    df['total_adult_crimes_bin'] = pd.cut(df['total_adult_crimes'], bins=bins, labels=labels, right=False)\n",
    "\n",
    "    return df\n",
    "\n",
    "# Load data (ensure df is loaded before this step)\n",
    "# df = pd.read_csv('your_data.csv')  # Example loading method\n",
    "\n",
    "# Apply preprocessing to the entire dataset\n",
    "df = preprocess_data(df)\n",
    "\n",
    "# Split data into train and test sets\n",
    "df_train, df_test = train_test_split(df, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define features\n",
    "all_features = [\n",
    "    \"sex\", \n",
    "    \"race\", \n",
    "    #\"juv_fel_count\", \n",
    "    #\"juv_misd_count\", \n",
    "    #\"juv_other_count\",\n",
    "    \"total_adult_crimes\", \n",
    "    \"c_charge_degree\", \n",
    "   # \"c_charge_desc\", \n",
    "    \"c_charge_desc_freq\",\n",
    "    \"age_at_unified_date\", \n",
    "    \"total_juv_crimes\",\n",
    "    \"offense_month\", \n",
    "    \"offense_day_of_week\", \n",
    "    \"arrest_month\", \n",
    "    \"arrest_day_of_week\",\n",
    "    \"age_group\",\n",
    "    \"priors_count_bin\"\n",
    "]\n",
    "\n",
    "numerical_features = [\n",
    "   # \"juv_fel_count\", \n",
    "    #\"juv_misd_count\", \n",
    "    #\"juv_other_count\", \n",
    "    \"total_adult_crimes\",\n",
    "    #\"time_offense_arrest\", \n",
    "    #\"time_since_jail_in\", \n",
    "    \"total_juv_crimes\",\n",
    "    \"offense_month\", \n",
    "    \"offense_day_of_week\", \n",
    "    \"arrest_month\", \n",
    "    \"arrest_day_of_week\",\n",
    "    \"age_at_unified_date\", \n",
    "    #\"age_birth\",\n",
    "    \"c_charge_desc_freq\",\n",
    "    #\"priors_count\"\n",
    "]\n",
    "\n",
    "categorical_features = [\n",
    "    \"sex\", \n",
    "    \"race\", \n",
    "    \"c_charge_degree\", \n",
    "   # \"c_charge_desc\",\n",
    "    \"age_group\",\n",
    "    \"priors_count_bin\",\n",
    "]\n",
    "\n",
    "target = 'is_recid'\n",
    "\n",
    "# Define preprocessing pipelines\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value='missing_value')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numerical_features),\n",
    "        ('cat', categorical_transformer, categorical_features)\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Use the best model parameters found earlier\n",
    "best_model_params = {\n",
    "    'learning_rate': 0.01,\n",
    "    'max_depth': 3,\n",
    "    'n_estimators': 300,\n",
    "    'subsample': 0.8,\n",
    "    'random_state': 42\n",
    "}\n",
    "\n",
    "pipeline = ImbPipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('smote', SMOTE(random_state=42)),\n",
    "    ('classifier', GradientBoostingClassifier(**best_model_params))\n",
    "])\n",
    "\n",
    "\n",
    "# Train the updated pipeline\n",
    "X_train = df_train[all_features]\n",
    "y_train = df_train[target]\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the updated pipeline on the test set\n",
    "X_test = df_test[all_features]\n",
    "y_test = df_test[target]\n",
    "y_pred = pipeline.predict(X_test)\n",
    "y_proba = pipeline.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "roc_auc = roc_auc_score(y_test, y_proba)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Print evaluation metrics\n",
    "print(f'Accuracy: {accuracy:.2f}')\n",
    "print(f'Precision: {precision:.2f}')\n",
    "print(f'Recall: {recall:.2f}')\n",
    "print(f'F1-Score: {f1:.2f}')\n",
    "print(f'ROC-AUC: {roc_auc:.2f}')\n",
    "print(f'Confusion Matrix:\\n{conf_matrix}')\n",
    "\n",
    "#####FAIRNESS#######\n",
    "import pandas as pd\n",
    "from fairlearn.metrics import (\n",
    "    demographic_parity_ratio, equalized_odds_ratio,\n",
    "    true_positive_rate_difference, false_positive_rate_difference,\n",
    "    selection_rate_difference\n",
    ")\n",
    "\n",
    "# Function to calculate fairness metrics for a given feature\n",
    "def calculate_fairness_metrics(y_test, y_pred, X_test, feature):\n",
    "    metrics = {\n",
    "        'Feature': feature,\n",
    "        'Disparate Impact Ratio': demographic_parity_ratio(y_true=y_test, y_pred=y_pred, sensitive_features=X_test[feature]),\n",
    "        'Equalized Odds Ratio': equalized_odds_ratio(y_true=y_test, y_pred=y_pred, sensitive_features=X_test[feature]),\n",
    "        'TPR Difference': true_positive_rate_difference(y_true=y_test, y_pred=y_pred, sensitive_features=X_test[feature]),\n",
    "        'FPR Difference': false_positive_rate_difference(y_true=y_test, y_pred=y_pred, sensitive_features=X_test[feature]),\n",
    "        'Selection Rate Difference': selection_rate_difference(y_true=y_test, y_pred=y_pred, sensitive_features=X_test[feature])\n",
    "    }\n",
    "    return metrics\n",
    "\n",
    "# Function to calculate disparate impact ratios by group for each sensitive feature\n",
    "def calculate_disparate_impact(y_true, y_pred, X_test, column):\n",
    "    disparate_impact_ratios = {}\n",
    "    overall_favorable_outcomes = y_pred.mean()\n",
    "    for value in X_test[column].unique():\n",
    "        mask = X_test[column] == value\n",
    "        favorable_outcomes = y_pred[mask].mean()\n",
    "        if overall_favorable_outcomes == 0:\n",
    "            disparate_impact_ratios[value] = np.nan\n",
    "        else:\n",
    "            disparate_impact_ratios[value] = favorable_outcomes / overall_favorable_outcomes\n",
    "    return disparate_impact_ratios\n",
    "\n",
    "# Create lists to store fairness metrics and disparate impact ratios\n",
    "fairness_metrics_list = []\n",
    "disparate_impact_list = []\n",
    "\n",
    "# Calculate fairness metrics for each feature\n",
    "features_to_check = ['sex', 'race', 'age_group', 'priors_count_bin']\n",
    "for feature in features_to_check:\n",
    "    metrics = calculate_fairness_metrics(y_test, y_pred, X_test, feature)\n",
    "    fairness_metrics_list.append(metrics)\n",
    "\n",
    "    # Calculate and store disparate impact ratios by group\n",
    "    disparate_impact_by_group = calculate_disparate_impact(y_test, y_pred, X_test, feature)\n",
    "    for group, ratio in disparate_impact_by_group.items():\n",
    "        disparate_impact_list.append({'Feature': feature, 'Group': group, 'Disparate Impact Ratio': ratio})\n",
    "\n",
    "# Convert lists to DataFrames\n",
    "fairness_metrics_df = pd.DataFrame(fairness_metrics_list)\n",
    "disparate_impact_df = pd.DataFrame(disparate_impact_list)\n",
    "\n",
    "# Reorder columns to have 'Feature' as the first column\n",
    "fairness_metrics_df = fairness_metrics_df[['Feature', 'Disparate Impact Ratio', 'Equalized Odds Ratio', 'TPR Difference', 'FPR Difference', 'Selection Rate Difference']]\n",
    "disparate_impact_df = disparate_impact_df[['Feature', 'Group', 'Disparate Impact Ratio']]\n",
    "\n",
    "# Format and print the DataFrames\n",
    "print(\"Fairness Metrics:\")\n",
    "print(fairness_metrics_df.round(2).to_string(index=False))\n",
    "\n",
    "print(\"\\nDisparate Impact Ratios by Group:\")\n",
    "print(disparate_impact_df.round(2).to_string(index=False))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27497cd8",
   "metadata": {},
   "source": [
    "##  Re-train with fairness constraints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "a62ca04c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install aif360\n",
    "#pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "b90e2b93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.68\n",
      "Precision: 0.67\n",
      "Recall: 0.58\n",
      "F1-Score: 0.62\n",
      "ROC-AUC: 0.67\n",
      "Confusion Matrix:\n",
      "[[492 152]\n",
      " [220 307]]\n",
      "Fairness Metrics:\n",
      "         Feature  Disparate Impact Ratio  Equalized Odds Ratio  TPR Difference  FPR Difference  Selection Rate Difference\n",
      "             sex                    0.94                  0.92            0.05            0.01                       0.02\n",
      "            race                    0.22                  0.00            1.00            0.33                       0.58\n",
      "       age_group                    0.00                  0.00            0.69            0.43                       0.56\n",
      "priors_count_bin                    0.09                  0.07            0.80            0.93                       0.88\n",
      "\n",
      "Disparate Impact Ratios by Group:\n",
      "         Feature            Group  Disparate Impact Ratio\n",
      "             sex             Male                    1.01\n",
      "             sex           Female                    0.96\n",
      "            race African-American                    1.28\n",
      "            race            Asian                    0.43\n",
      "            race        Caucasian                    0.68\n",
      "            race            Other                    0.83\n",
      "            race         Hispanic                    0.73\n",
      "            race  Native American                    1.91\n",
      "       age_group            36-45                    1.27\n",
      "       age_group            26-35                    1.43\n",
      "       age_group            56-65                    0.48\n",
      "       age_group            46-55                    0.39\n",
      "       age_group              66+                    0.50\n",
      "       age_group    missing_value                    0.00\n",
      "priors_count_bin              10+                    2.47\n",
      "priors_count_bin              3-4                    1.72\n",
      "priors_count_bin                0                    0.23\n",
      "priors_count_bin              1-2                    0.63\n",
      "priors_count_bin              5-9                    1.58\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix\n",
    ")\n",
    "from fairlearn.reductions import ExponentiatedGradient, DemographicParity\n",
    "from fairlearn.metrics import (\n",
    "    demographic_parity_ratio, equalized_odds_ratio,\n",
    "    true_positive_rate_difference, false_positive_rate_difference,\n",
    "    selection_rate_difference\n",
    ")\n",
    "\n",
    "# Define the categorize_charge function\n",
    "def frequency_encoding(df, column):\n",
    "    freq_encoding = df[column].value_counts(normalize=True)\n",
    "    df[f'{column}_freq'] = df[column].map(freq_encoding)\n",
    "    return df\n",
    "\n",
    "# Define the preprocess_data function\n",
    "def preprocess_data(df):\n",
    "    df['dob'] = pd.to_datetime(df['dob'])\n",
    "    df['c_offense_date'] = pd.to_datetime(df['c_offense_date'])\n",
    "    df['c_arrest_date'] = pd.to_datetime(df['c_arrest_date'])\n",
    "    df['c_jail_in'] = pd.to_datetime(df['c_jail_in'])\n",
    "\n",
    "    # Create unified_date\n",
    "    df['unified_date'] = df['c_arrest_date'].combine_first(df['c_offense_date'])\n",
    "\n",
    "    # Feature engineering\n",
    "    df['age_birth'] = (pd.to_datetime('today') - df['dob']).dt.days // 365\n",
    "    df['age_at_unified_date'] = (df['unified_date'] - df['dob']).dt.days // 365\n",
    "\n",
    "    # Calculate averages for filling NaN values\n",
    "    avg_time_offense_arrest = (df['c_arrest_date'] - df['c_offense_date']).dt.days.mean()\n",
    "    avg_time_since_jail_in = (pd.to_datetime('today') - df['c_jail_in']).dt.days.mean()\n",
    "    avg_time_to_jail = (df['c_jail_in'] - df['unified_date']).dt.days.mean()\n",
    "\n",
    "    df['time_offense_arrest'] = (df['c_arrest_date'] - df['c_offense_date']).dt.days.fillna(avg_time_offense_arrest)\n",
    "    df['time_since_jail_in'] = (pd.to_datetime('today') - df['c_jail_in']).dt.days.fillna(avg_time_since_jail_in)\n",
    "    df['time_to_jail'] = (df['c_jail_in'] - df['unified_date']).dt.days.fillna(avg_time_to_jail)\n",
    "    \n",
    "    df['total_juv_crimes'] = df['juv_fel_count'] + df['juv_misd_count'] + df['juv_other_count']\n",
    "    df['total_adult_crimes'] = df['priors_count'] - df['total_juv_crimes']\n",
    "\n",
    "    # Apply frequency encoding and group less frequent categories\n",
    "    df = frequency_encoding(df, 'c_charge_desc')\n",
    "\n",
    "    # Create age bins and handle missing values\n",
    "    bins = [18, 25, 35, 45, 55, 65, 100]\n",
    "    labels = ['18-25', '26-35', '36-45', '46-55', '56-65', '66+']\n",
    "    df['age_group'] = pd.cut(df['age_birth'], bins=bins, labels=labels, right=False)\n",
    "    df['age_group'] = df['age_group'].cat.add_categories('missing_value').fillna('missing_value')\n",
    "    \n",
    "    # Extract more granular date features\n",
    "    df['offense_month'] = df['c_offense_date'].dt.month.fillna(df['c_offense_date'].dt.month.mean())\n",
    "    df['offense_day_of_week'] = df['c_offense_date'].dt.dayofweek.fillna(df['c_offense_date'].dt.dayofweek.mean())\n",
    "    df['arrest_month'] = df['c_arrest_date'].dt.month.fillna(df['c_arrest_date'].dt.month.mean())\n",
    "    df['arrest_day_of_week'] = df['c_arrest_date'].dt.dayofweek.fillna(df['c_arrest_date'].dt.dayofweek.mean())\n",
    "\n",
    "    # Binning total_adult_crimes\n",
    "    df['total_adult_crimes'] = df['total_adult_crimes'].apply(lambda x: max(0, x)).astype(float)\n",
    "    bins = [0, 1, 3, 5, 10, np.inf]\n",
    "    labels = ['0', '1-2', '3-4', '5-9', '10+']\n",
    "    df['priors_count_bin'] = pd.cut(df['priors_count'], bins=bins, labels=labels, right=False)\n",
    "\n",
    "    return df\n",
    "\n",
    "# Load data and preprocess\n",
    "\n",
    "df = preprocess_data(df)\n",
    "\n",
    "# Split data into train and test sets\n",
    "df_train, df_test = train_test_split(df, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define features\n",
    "all_features = [\n",
    "    \"sex\", \"race\", \"priors_count_bin\", \"c_charge_degree\",\n",
    "    \"c_charge_desc_freq\", \"age_at_unified_date\", \"total_juv_crimes\",\n",
    "    \"offense_month\", \"offense_day_of_week\", \"arrest_month\", \"arrest_day_of_week\"\n",
    "]\n",
    "\n",
    "numerical_features = [\n",
    "    \"total_juv_crimes\", \"offense_month\", \"offense_day_of_week\",\n",
    "    \"arrest_month\", \"arrest_day_of_week\", \"age_at_unified_date\",\n",
    "    \"c_charge_desc_freq\"\n",
    "]\n",
    "\n",
    "categorical_features = [\"sex\", \"race\", \"c_charge_degree\", \"priors_count_bin\"]\n",
    "\n",
    "target = 'is_recid'\n",
    "\n",
    "# Define preprocessing pipelines\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value='missing_value')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numerical_features),\n",
    "        ('cat', categorical_transformer, categorical_features)\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Use the best model parameters found earlier\n",
    "best_model_params = {\n",
    "    'learning_rate': 0.01,\n",
    "    'max_depth': 3,\n",
    "    'n_estimators': 300,\n",
    "    'subsample': 0.8,\n",
    "    'random_state': 42\n",
    "}\n",
    "\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', GradientBoostingClassifier(**best_model_params))\n",
    "])\n",
    "\n",
    "# Train the updated pipeline without fairness constraints first\n",
    "X_train = df_train[all_features]\n",
    "y_train = df_train[target]\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Transform the features\n",
    "X_train_transformed = pipeline.named_steps['preprocessor'].transform(X_train)\n",
    "X_test_transformed = pipeline.named_steps['preprocessor'].transform(df_test[all_features])\n",
    "\n",
    "# Re-train with fairness constraints\n",
    "estimator = GradientBoostingClassifier(**best_model_params)\n",
    "constraint = DemographicParity()\n",
    "mitigator = ExponentiatedGradient(estimator, constraints=constraint)\n",
    "mitigator.fit(X_train_transformed, y_train, sensitive_features=X_train['sex'])\n",
    "\n",
    "# Evaluate the updated pipeline on the test set\n",
    "y_test = df_test[target]\n",
    "y_pred = mitigator.predict(X_test_transformed)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "roc_auc = roc_auc_score(y_test, y_pred)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Print evaluation metrics\n",
    "print(f'Accuracy: {accuracy:.2f}')\n",
    "print(f'Precision: {precision:.2f}')\n",
    "print(f'Recall: {recall:.2f}')\n",
    "print(f'F1-Score: {f1:.2f}')\n",
    "print(f'ROC-AUC: {roc_auc:.2f}')\n",
    "print(f'Confusion Matrix:\\n{conf_matrix}')\n",
    "\n",
    "#####FAIRNESS#######\n",
    "import pandas as pd\n",
    "from fairlearn.metrics import (\n",
    "    demographic_parity_ratio, equalized_odds_ratio,\n",
    "    true_positive_rate_difference, false_positive_rate_difference,\n",
    "    selection_rate_difference\n",
    ")\n",
    "\n",
    "# Function to calculate fairness metrics for a given feature\n",
    "def calculate_fairness_metrics(y_test, y_pred, X_test, feature):\n",
    "    metrics = {\n",
    "        'Feature': feature,\n",
    "        'Disparate Impact Ratio': demographic_parity_ratio(y_true=y_test, y_pred=y_pred, sensitive_features=X_test[feature]),\n",
    "        'Equalized Odds Ratio': equalized_odds_ratio(y_true=y_test, y_pred=y_pred, sensitive_features=X_test[feature]),\n",
    "        'TPR Difference': true_positive_rate_difference(y_true=y_test, y_pred=y_pred, sensitive_features=X_test[feature]),\n",
    "        'FPR Difference': false_positive_rate_difference(y_true=y_test, y_pred=y_pred, sensitive_features=X_test[feature]),\n",
    "        'Selection Rate Difference': selection_rate_difference(y_true=y_test, y_pred=y_pred, sensitive_features=X_test[feature])\n",
    "    }\n",
    "    return metrics\n",
    "\n",
    "# Function to calculate disparate impact ratios by group for each sensitive feature\n",
    "def calculate_disparate_impact(y_true, y_pred, X_test, column):\n",
    "    disparate_impact_ratios = {}\n",
    "    overall_favorable_outcomes = y_pred.mean()\n",
    "    for value in X_test[column].unique():\n",
    "        mask = X_test[column] == value\n",
    "        favorable_outcomes = y_pred[mask].mean()\n",
    "        if overall_favorable_outcomes == 0:\n",
    "            disparate_impact_ratios[value] = np.nan\n",
    "        else:\n",
    "            disparate_impact_ratios[value] = favorable_outcomes / overall_favorable_outcomes\n",
    "    return disparate_impact_ratios\n",
    "\n",
    "# Create lists to store fairness metrics and disparate impact ratios\n",
    "fairness_metrics_list = []\n",
    "disparate_impact_list = []\n",
    "\n",
    "# Calculate fairness metrics for each feature\n",
    "features_to_check = ['sex', 'race', 'age_group', 'priors_count_bin']\n",
    "for feature in features_to_check:\n",
    "    metrics = calculate_fairness_metrics(y_test, y_pred, X_test, feature)\n",
    "    fairness_metrics_list.append(metrics)\n",
    "\n",
    "    # Calculate and store disparate impact ratios by group\n",
    "    disparate_impact_by_group = calculate_disparate_impact(y_test, y_pred, X_test, feature)\n",
    "    for group, ratio in disparate_impact_by_group.items():\n",
    "        disparate_impact_list.append({'Feature': feature, 'Group': group, 'Disparate Impact Ratio': ratio})\n",
    "\n",
    "# Convert lists to DataFrames\n",
    "fairness_metrics_df = pd.DataFrame(fairness_metrics_list)\n",
    "disparate_impact_df = pd.DataFrame(disparate_impact_list)\n",
    "\n",
    "# Reorder columns to have 'Feature' as the first column\n",
    "fairness_metrics_df = fairness_metrics_df[['Feature', 'Disparate Impact Ratio', 'Equalized Odds Ratio', 'TPR Difference', 'FPR Difference', 'Selection Rate Difference']]\n",
    "disparate_impact_df = disparate_impact_df[['Feature', 'Group', 'Disparate Impact Ratio']]\n",
    "\n",
    "# Format and print the DataFrames\n",
    "print(\"Fairness Metrics:\")\n",
    "print(fairness_metrics_df.round(2).to_string(index=False))\n",
    "\n",
    "print(\"\\nDisparate Impact Ratios by Group:\")\n",
    "print(disparate_impact_df.round(2).to_string(index=False))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0783b677",
   "metadata": {},
   "source": [
    "## Reweighing Technique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "11e72bcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.66\n",
      "Precision: 0.65\n",
      "Recall: 0.51\n",
      "F1-Score: 0.57\n",
      "ROC-AUC: 0.73\n",
      "Confusion Matrix:\n",
      "[[500 144]\n",
      " [257 270]]\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'sex'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/indexes/base.py:3790\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3789\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3790\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3791\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32mindex.pyx:152\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mindex.pyx:181\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7080\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7088\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'sex'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[163], line 222\u001b[0m\n\u001b[1;32m    220\u001b[0m features_to_check \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msex\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrace\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mage_group\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpriors_count_bin\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m    221\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m feature \u001b[38;5;129;01min\u001b[39;00m features_to_check:\n\u001b[0;32m--> 222\u001b[0m     metrics \u001b[38;5;241m=\u001b[39m \u001b[43mcalculate_fairness_metrics\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeature\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    223\u001b[0m     fairness_metrics_list\u001b[38;5;241m.\u001b[39mappend(metrics)\n\u001b[1;32m    225\u001b[0m     \u001b[38;5;66;03m# Calculate and store disparate impact ratios by group\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[163], line 194\u001b[0m, in \u001b[0;36mcalculate_fairness_metrics\u001b[0;34m(y_test, y_pred, X_test, feature)\u001b[0m\n\u001b[1;32m    191\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcalculate_fairness_metrics\u001b[39m(y_test, y_pred, X_test, feature):\n\u001b[1;32m    192\u001b[0m     metrics \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    193\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFeature\u001b[39m\u001b[38;5;124m'\u001b[39m: feature,\n\u001b[0;32m--> 194\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDisparate Impact Ratio\u001b[39m\u001b[38;5;124m'\u001b[39m: demographic_parity_ratio(y_true\u001b[38;5;241m=\u001b[39my_test, y_pred\u001b[38;5;241m=\u001b[39my_pred, sensitive_features\u001b[38;5;241m=\u001b[39m\u001b[43mX_test\u001b[49m\u001b[43m[\u001b[49m\u001b[43mfeature\u001b[49m\u001b[43m]\u001b[49m),\n\u001b[1;32m    195\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEqualized Odds Ratio\u001b[39m\u001b[38;5;124m'\u001b[39m: equalized_odds_ratio(y_true\u001b[38;5;241m=\u001b[39my_test, y_pred\u001b[38;5;241m=\u001b[39my_pred, sensitive_features\u001b[38;5;241m=\u001b[39mX_test[feature]),\n\u001b[1;32m    196\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTPR Difference\u001b[39m\u001b[38;5;124m'\u001b[39m: true_positive_rate_difference(y_true\u001b[38;5;241m=\u001b[39my_test, y_pred\u001b[38;5;241m=\u001b[39my_pred, sensitive_features\u001b[38;5;241m=\u001b[39mX_test[feature]),\n\u001b[1;32m    197\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFPR Difference\u001b[39m\u001b[38;5;124m'\u001b[39m: false_positive_rate_difference(y_true\u001b[38;5;241m=\u001b[39my_test, y_pred\u001b[38;5;241m=\u001b[39my_pred, sensitive_features\u001b[38;5;241m=\u001b[39mX_test[feature]),\n\u001b[1;32m    198\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSelection Rate Difference\u001b[39m\u001b[38;5;124m'\u001b[39m: selection_rate_difference(y_true\u001b[38;5;241m=\u001b[39my_test, y_pred\u001b[38;5;241m=\u001b[39my_pred, sensitive_features\u001b[38;5;241m=\u001b[39mX_test[feature])\n\u001b[1;32m    199\u001b[0m     }\n\u001b[1;32m    200\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m metrics\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/frame.py:3896\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3894\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   3895\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 3896\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3897\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   3898\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/indexes/base.py:3797\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3792\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[1;32m   3793\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[1;32m   3794\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[1;32m   3795\u001b[0m     ):\n\u001b[1;32m   3796\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[0;32m-> 3797\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3798\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3799\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3800\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3801\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3802\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'sex'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix\n",
    "from fairlearn.metrics import (\n",
    "    demographic_parity_ratio, equalized_odds_ratio,\n",
    "    true_positive_rate_difference, false_positive_rate_difference,\n",
    "    selection_rate_difference\n",
    ")\n",
    "\n",
    "# Define preprocess_data function to include binning for total_adult_crimes\n",
    "def preprocess_data(df):\n",
    "    df['dob'] = pd.to_datetime(df['dob'])\n",
    "    df['c_offense_date'] = pd.to_datetime(df['c_offense_date'])\n",
    "    df['c_arrest_date'] = pd.to_datetime(df['c_arrest_date'])\n",
    "    df['c_jail_in'] = pd.to_datetime(df['c_jail_in'])\n",
    "\n",
    "    df['unified_date'] = df['c_arrest_date'].combine_first(df['c_offense_date'])\n",
    "\n",
    "    df['age_birth'] = (pd.to_datetime('today') - df['dob']).dt.days // 365\n",
    "    df['age_at_unified_date'] = (df['unified_date'] - df['dob']).dt.days // 365\n",
    "    \n",
    "    avg_time_offense_arrest = (df['c_arrest_date'] - df['c_offense_date']).dt.days.mean()\n",
    "    avg_time_since_jail_in = (pd.to_datetime('today') - df['c_jail_in']).dt.days.mean()\n",
    "    avg_time_to_jail = (df['c_jail_in'] - df['unified_date']).dt.days.mean()\n",
    "\n",
    "    df['time_offense_arrest'] = (df['c_arrest_date'] - df['c_offense_date']).dt.days.fillna(avg_time_offense_arrest)\n",
    "    df['time_since_jail_in'] = (pd.to_datetime('today') - df['c_jail_in']).dt.days.fillna(avg_time_since_jail_in)\n",
    "    df['time_to_jail'] = (df['c_jail_in'] - df['unified_date']).dt.days.fillna(avg_time_to_jail)\n",
    "    \n",
    "    df['total_juv_crimes'] = df['juv_fel_count'] + df['juv_misd_count'] + df['juv_other_count']\n",
    "    df['total_adult_crimes'] = df['priors_count'] - df['total_juv_crimes']\n",
    "    \n",
    "    # Apply frequency encoding\n",
    "    df['c_charge_desc_freq'] = df['c_charge_desc'].map(df['c_charge_desc'].value_counts(normalize=True))\n",
    "\n",
    "    # Create age bins and handle missing values\n",
    "    bins = [18, 25, 35, 45, 55, 65, 100]\n",
    "    labels = ['18-25', '26-35', '36-45', '46-55', '56-65', '66+']\n",
    "    df['age_group'] = pd.cut(df['age_birth'], bins=bins, labels=labels, right=False)\n",
    "    df['age_group'] = df['age_group'].cat.add_categories('missing_value').fillna('missing_value')\n",
    "    \n",
    "    \n",
    "    # Create bins for total_adult_crimes\n",
    "    bins = [-np.inf, 0, 1, 3, 5, 10, np.inf]\n",
    "    labels = ['<0', '0', '1-2', '3-4', '5-9', '10+']\n",
    "    df['total_adult_crimes_bin'] = pd.cut(df['total_adult_crimes'], bins=bins, labels=labels)\n",
    "\n",
    "    # Encode categorical variables\n",
    "    df['sex_encoded'] = df['sex'].map({'Male': 1, 'Female': 0})\n",
    "    df['race_encoded'] = df['race'].astype('category').cat.codes\n",
    "    df['priors_count_bin'] = pd.cut(df['priors_count'], bins=bins, labels=labels, right=False)\n",
    "\n",
    "    return df\n",
    "\n",
    "# Assuming df is already loaded and preprocessed\n",
    "# Apply preprocessing to the entire dataset\n",
    "df = preprocess_data(df)\n",
    "\n",
    "# Split data into train and test sets\n",
    "df_train, df_test = train_test_split(df, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define features\n",
    "all_features = [\n",
    "    #\"sex\", \n",
    "    \"race\", \n",
    "    \"priors_count_bin\", \n",
    "    \"c_charge_degree\", \n",
    "    \"c_charge_desc_freq\",\n",
    "    \"age_at_unified_date\", \n",
    "    \"total_juv_crimes\",\n",
    "    \"offense_month\", \n",
    "    \"offense_day_of_week\", \n",
    "    \"arrest_month\", \n",
    "    \"arrest_day_of_week\",\n",
    "    \"age_group\"\n",
    "]\n",
    "\n",
    "numerical_features = [\n",
    "    \"total_juv_crimes\",\n",
    "    \"offense_month\", \n",
    "    \"offense_day_of_week\", \n",
    "    \"arrest_month\", \n",
    "    \"arrest_day_of_week\",\n",
    "    \"age_at_unified_date\", \n",
    "    \"c_charge_desc_freq\"\n",
    "]\n",
    "\n",
    "categorical_features = [\n",
    "    #\"sex\", \n",
    "    \"race\", \n",
    "    \"priors_count_bin\", \n",
    "    \"c_charge_degree\",\n",
    "    \"age_group\"\n",
    "]\n",
    "\n",
    "target = 'is_recid'\n",
    "\n",
    "# Define preprocessing pipelines\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value='missing_value')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numerical_features),\n",
    "        ('cat', categorical_transformer, categorical_features)\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Use the best model parameters found earlier\n",
    "best_model_params = {\n",
    "    'learning_rate': 0.01,\n",
    "    'max_depth': 3,\n",
    "    'n_estimators': 300,\n",
    "    'subsample': 0.8,\n",
    "    'random_state': 42\n",
    "}\n",
    "\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', GradientBoostingClassifier(**best_model_params))\n",
    "])\n",
    "\n",
    "# Compute sample weights for multiple sensitive attributes\n",
    "def compute_combined_sample_weights(df, sensitive_features):\n",
    "    sample_weights = np.ones(len(df))\n",
    "    for feature in sensitive_features:\n",
    "        counts = df[feature].value_counts()\n",
    "        weights = 1 / counts\n",
    "        feature_weights = df[feature].map(weights)\n",
    "        sample_weights *= feature_weights\n",
    "    \n",
    "    # Normalize weights\n",
    "    sample_weights /= np.sum(sample_weights) / len(sample_weights)\n",
    "    return sample_weights\n",
    "\n",
    "# Compute combined sample weights\n",
    "sensitive_features = ['race_encoded']\n",
    "sample_weights = compute_combined_sample_weights(df_train, sensitive_features)\n",
    "\n",
    "# Fit the model using manually computed sample weights\n",
    "X_train = df_train[all_features]\n",
    "y_train = df_train[target]\n",
    "pipeline.fit(X_train, y_train, classifier__sample_weight=sample_weights)\n",
    "\n",
    "# Evaluate the updated pipeline on the test set\n",
    "X_test = df_test[all_features]\n",
    "y_test = df_test[target]\n",
    "\n",
    "# Predictions\n",
    "y_pred = pipeline.predict(X_test)\n",
    "y_proba = pipeline.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "roc_auc = roc_auc_score(y_test, y_proba)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Print evaluation metrics\n",
    "print(f'Accuracy: {accuracy:.2f}')\n",
    "print(f'Precision: {precision:.2f}')\n",
    "print(f'Recall: {recall:.2f}')\n",
    "print(f'F1-Score: {f1:.2f}')\n",
    "print(f'ROC-AUC: {roc_auc:.2f}')\n",
    "print(f'Confusion Matrix:\\n{conf_matrix}')\n",
    "\n",
    "#####FAIRNESS#######\n",
    "import pandas as pd\n",
    "from fairlearn.metrics import (\n",
    "    demographic_parity_ratio, equalized_odds_ratio,\n",
    "    true_positive_rate_difference, false_positive_rate_difference,\n",
    "    selection_rate_difference\n",
    ")\n",
    "\n",
    "# Function to calculate fairness metrics for a given feature\n",
    "def calculate_fairness_metrics(y_test, y_pred, X_test, feature):\n",
    "    metrics = {\n",
    "        'Feature': feature,\n",
    "        'Disparate Impact Ratio': demographic_parity_ratio(y_true=y_test, y_pred=y_pred, sensitive_features=X_test[feature]),\n",
    "        'Equalized Odds Ratio': equalized_odds_ratio(y_true=y_test, y_pred=y_pred, sensitive_features=X_test[feature]),\n",
    "        'TPR Difference': true_positive_rate_difference(y_true=y_test, y_pred=y_pred, sensitive_features=X_test[feature]),\n",
    "        'FPR Difference': false_positive_rate_difference(y_true=y_test, y_pred=y_pred, sensitive_features=X_test[feature]),\n",
    "        'Selection Rate Difference': selection_rate_difference(y_true=y_test, y_pred=y_pred, sensitive_features=X_test[feature])\n",
    "    }\n",
    "    return metrics\n",
    "\n",
    "# Function to calculate disparate impact ratios by group for each sensitive feature\n",
    "def calculate_disparate_impact(y_true, y_pred, X_test, column):\n",
    "    disparate_impact_ratios = {}\n",
    "    overall_favorable_outcomes = y_pred.mean()\n",
    "    for value in X_test[column].unique():\n",
    "        mask = X_test[column] == value\n",
    "        favorable_outcomes = y_pred[mask].mean()\n",
    "        if overall_favorable_outcomes == 0:\n",
    "            disparate_impact_ratios[value] = np.nan\n",
    "        else:\n",
    "            disparate_impact_ratios[value] = favorable_outcomes / overall_favorable_outcomes\n",
    "    return disparate_impact_ratios\n",
    "\n",
    "# Create lists to store fairness metrics and disparate impact ratios\n",
    "fairness_metrics_list = []\n",
    "disparate_impact_list = []\n",
    "\n",
    "# Calculate fairness metrics for each feature\n",
    "features_to_check = ['sex', 'race', 'age_group', 'priors_count_bin']\n",
    "for feature in features_to_check:\n",
    "    metrics = calculate_fairness_metrics(y_test, y_pred, X_test, feature)\n",
    "    fairness_metrics_list.append(metrics)\n",
    "\n",
    "    # Calculate and store disparate impact ratios by group\n",
    "    disparate_impact_by_group = calculate_disparate_impact(y_test, y_pred, X_test, feature)\n",
    "    for group, ratio in disparate_impact_by_group.items():\n",
    "        disparate_impact_list.append({'Feature': feature, 'Group': group, 'Disparate Impact Ratio': ratio})\n",
    "\n",
    "# Convert lists to DataFrames\n",
    "fairness_metrics_df = pd.DataFrame(fairness_metrics_list)\n",
    "disparate_impact_df = pd.DataFrame(disparate_impact_list)\n",
    "\n",
    "# Reorder columns to have 'Feature' as the first column\n",
    "fairness_metrics_df = fairness_metrics_df[['Feature', 'Disparate Impact Ratio', 'Equalized Odds Ratio', 'TPR Difference', 'FPR Difference', 'Selection Rate Difference']]\n",
    "disparate_impact_df = disparate_impact_df[['Feature', 'Group', 'Disparate Impact Ratio']]\n",
    "\n",
    "# Format and print the DataFrames\n",
    "print(\"Fairness Metrics:\")\n",
    "print(fairness_metrics_df.round(2).to_string(index=False))\n",
    "\n",
    "print(\"\\nDisparate Impact Ratios by Group:\")\n",
    "print(disparate_impact_df.round(2).to_string(index=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "f2920687",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.69\n",
      "Precision: 0.67\n",
      "Recall: 0.60\n",
      "F1-Score: 0.63\n",
      "ROC-AUC: 0.74\n",
      "Confusion Matrix:\n",
      "[[487 157]\n",
      " [211 316]]\n",
      "\n",
      "Fairness metrics for race:\n",
      "Disparate Impact Ratio: 0.22\n",
      "Equalized Odds Ratio: 0.00\n",
      "True Positive Rate Difference: 1.00\n",
      "False Positive Rate Difference: 0.32\n",
      "Selection Rate Difference: 0.58\n",
      "\n",
      "Disparate Impact Ratios by Sex:\n",
      "Male: 1.11\n",
      "Female: 0.58\n",
      "\n",
      "Disparate Impact Ratios by Race:\n",
      "African-American: 1.26\n",
      "Asian: 0.41\n",
      "Caucasian: 0.67\n",
      "Other: 0.86\n",
      "Hispanic: 0.86\n",
      "Native American: 1.86\n",
      "\n",
      "Disparate Impact Ratios by Total_adult_crimes_bin:\n",
      "10+: 2.45\n",
      "3-4: 1.69\n",
      "<0: 0.45\n",
      "1-2: 1.27\n",
      "0: 0.19\n",
      "5-9: 1.86\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix\n",
    ")\n",
    "from fairlearn.preprocessing import CorrelationRemover\n",
    "from fairlearn.metrics import (\n",
    "    demographic_parity_ratio, equalized_odds_ratio,\n",
    "    true_positive_rate_difference, false_positive_rate_difference,\n",
    "    selection_rate_difference\n",
    ")\n",
    "import joblib\n",
    "\n",
    "# Define preprocess_data function to include binning for total_adult_crimes\n",
    "def preprocess_data(df):\n",
    "    df['dob'] = pd.to_datetime(df['dob'])\n",
    "    df['c_offense_date'] = pd.to_datetime(df['c_offense_date'])\n",
    "    df['c_arrest_date'] = pd.to_datetime(df['c_arrest_date'])\n",
    "    df['c_jail_in'] = pd.to_datetime(df['c_jail_in'])\n",
    "\n",
    "    df['unified_date'] = df['c_arrest_date'].combine_first(df['c_offense_date'])\n",
    "\n",
    "    df['age_birth'] = (pd.to_datetime('today') - df['dob']).dt.days // 365\n",
    "    df['age_at_unified_date'] = (df['unified_date'] - df['dob']).dt.days // 365\n",
    "    \n",
    "    avg_time_offense_arrest = (df['c_arrest_date'] - df['c_offense_date']).dt.days.mean()\n",
    "    avg_time_since_jail_in = (pd.to_datetime('today') - df['c_jail_in']).dt.days.mean()\n",
    "    avg_time_to_jail = (df['c_jail_in'] - df['unified_date']).dt.days.mean()\n",
    "\n",
    "    df['time_offense_arrest'] = (df['c_arrest_date'] - df['c_offense_date']).dt.days.fillna(avg_time_offense_arrest)\n",
    "    df['time_since_jail_in'] = (pd.to_datetime('today') - df['c_jail_in']).dt.days.fillna(avg_time_since_jail_in)\n",
    "    df['time_to_jail'] = (df['c_jail_in'] - df['unified_date']).dt.days.fillna(avg_time_to_jail)\n",
    "    \n",
    "    df['total_juv_crimes'] = df['juv_fel_count'] + df['juv_misd_count'] + df['juv_other_count']\n",
    "    df['total_adult_crimes'] = df['priors_count'] - df['total_juv_crimes']\n",
    "    \n",
    "    # Apply frequency encoding\n",
    "    df['c_charge_desc_freq'] = df['c_charge_desc'].map(df['c_charge_desc'].value_counts(normalize=True))\n",
    "\n",
    "    # Create bins for total_adult_crimes\n",
    "    bins = [-np.inf, 0, 1, 3, 5, 10, np.inf]\n",
    "    labels = ['<0', '0', '1-2', '3-4', '5-9', '10+']\n",
    "    df['total_adult_crimes_bin'] = pd.cut(df['total_adult_crimes'], bins=bins, labels=labels)\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Assuming df is already loaded and preprocessed\n",
    "# Apply preprocessing to the entire dataset\n",
    "df = preprocess_data(df)\n",
    "\n",
    "# Split data into train and test sets\n",
    "df_train, df_test = train_test_split(df, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define features\n",
    "all_features = [\n",
    "    \"sex\", \n",
    "    \"race\", \n",
    "    \"total_adult_crimes_bin\", \n",
    "    \"c_charge_degree\", \n",
    "    \"c_charge_desc_freq\",\n",
    "    \"age_at_unified_date\", \n",
    "    \"total_juv_crimes\",\n",
    "    \"offense_month\", \n",
    "    \"offense_day_of_week\", \n",
    "    \"arrest_month\", \n",
    "    \"arrest_day_of_week\"\n",
    "]\n",
    "\n",
    "numerical_features = [\n",
    "    \"total_juv_crimes\",\n",
    "    \"offense_month\", \n",
    "    \"offense_day_of_week\", \n",
    "    \"arrest_month\", \n",
    "    \"arrest_day_of_week\",\n",
    "    \"age_at_unified_date\", \n",
    "    \"c_charge_desc_freq\"\n",
    "]\n",
    "\n",
    "categorical_features = [\n",
    "    \"sex\", \n",
    "    \"race\", \n",
    "    \"total_adult_crimes_bin\", \n",
    "    \"c_charge_degree\"\n",
    "]\n",
    "\n",
    "target = 'is_recid'\n",
    "\n",
    "# Define preprocessing pipelines\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value='missing_value')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numerical_features),\n",
    "        ('cat', categorical_transformer, categorical_features)\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fair representation learning\n",
    "fair_representation = CorrelationRemover(sensitive_feature_ids=[0, 1])  # Indices of sensitive features (sex and race)\n",
    "\n",
    "# Use the best model parameters found earlier\n",
    "best_model_params = {\n",
    "    'learning_rate': 0.01,\n",
    "    'max_depth': 3,\n",
    "    'n_estimators': 300,\n",
    "    'subsample': 0.8,\n",
    "    'random_state': 42\n",
    "}\n",
    "\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('fair_representation', fair_representation),\n",
    "    ('classifier', GradientBoostingClassifier(**best_model_params))\n",
    "])\n",
    "\n",
    "# Fit the model\n",
    "X_train = df_train[all_features]\n",
    "y_train = df_train[target]\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the updated pipeline on the test set\n",
    "X_test = df_test[all_features]\n",
    "y_test = df_test[target]\n",
    "\n",
    "# Predictions\n",
    "y_pred = pipeline.predict(X_test)\n",
    "y_proba = pipeline.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "roc_auc = roc_auc_score(y_test, y_proba)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Print evaluation metrics\n",
    "print(f'Accuracy: {accuracy:.2f}')\n",
    "print(f'Precision: {precision:.2f}')\n",
    "print(f'Recall: {recall:.2f}')\n",
    "print(f'F1-Score: {f1:.2f}')\n",
    "print(f'ROC-AUC: {roc_auc:.2f}')\n",
    "print(f'Confusion Matrix:\\n{conf_matrix}')\n",
    "\n",
    "# Fairness metrics\n",
    "for feature in ['race']:\n",
    "    print(f\"\\nFairness metrics for {feature}:\")\n",
    "    disparate_impact = demographic_parity_ratio(y_true=y_test, y_pred=y_pred, sensitive_features=X_test[feature])\n",
    "    equalized_odds = equalized_odds_ratio(y_true=y_test, y_pred=y_pred, sensitive_features=X_test[feature])\n",
    "    tpr_diff = true_positive_rate_difference(y_true=y_test, y_pred=y_pred, sensitive_features=X_test[feature])\n",
    "    fpr_diff = false_positive_rate_difference(y_true=y_test, y_pred=y_pred, sensitive_features=X_test[feature])\n",
    "    selection_rate_diff = selection_rate_difference(y_true=y_test, y_pred=y_pred, sensitive_features=X_test[feature])\n",
    "    print(f\"Disparate Impact Ratio: {disparate_impact:.2f}\")\n",
    "    print(f\"Equalized Odds Ratio: {equalized_odds:.2f}\")\n",
    "    print(f\"True Positive Rate Difference: {tpr_diff:.2f}\")\n",
    "    print(f\"False Positive Rate Difference: {fpr_diff:.2f}\")\n",
    "    print(f\"Selection Rate Difference: {selection_rate_diff:.2f}\")\n",
    "\n",
    "# Disparate impact ratios by group for each sensitive feature\n",
    "def calculate_disparate_impact(y_true, y_pred, X_test, column):\n",
    "    disparate_impact_ratios = {}\n",
    "    overall_favorable_outcomes = y_pred.mean()\n",
    "    for value in X_test[column].unique():\n",
    "        mask = X_test[column] == value\n",
    "        favorable_outcomes = y_pred[mask].mean()\n",
    "        if overall_favorable_outcomes == 0:\n",
    "            disparate_impact_ratios[value] = np.nan\n",
    "        else:\n",
    "            disparate_impact_ratios[value] = favorable_outcomes / overall_favorable_outcomes\n",
    "    return disparate_impact_ratios\n",
    "\n",
    "for feature in ['sex', 'race', 'total_adult_crimes_bin']:\n",
    "    disparate_impact_by_group = calculate_disparate_impact(y_test, y_pred, X_test, feature)\n",
    "    print(f\"\\nDisparate Impact Ratios by {feature.capitalize()}:\")\n",
    "    for group, ratio in disparate_impact_by_group.items():\n",
    "        print(f\"{group}: {ratio:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef894316",
   "metadata": {},
   "outputs": [],
   "source": [
    "## ANOTHER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "41db2a9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.67\n",
      "Precision: 0.62\n",
      "Recall: 0.68\n",
      "F1-Score: 0.65\n",
      "ROC-AUC: 0.74\n",
      "Confusion Matrix:\n",
      "[[424 220]\n",
      " [167 360]]\n",
      "\n",
      "Fairness metrics for sex:\n",
      "Disparate Impact Ratio: 0.59\n",
      "Equalized Odds Ratio: 0.52\n",
      "True Positive Rate Difference: 0.17\n",
      "False Positive Rate Difference: 0.18\n",
      "Selection Rate Difference: 0.22\n",
      "\n",
      "Fairness metrics for race:\n",
      "Disparate Impact Ratio: 0.22\n",
      "Equalized Odds Ratio: 0.00\n",
      "True Positive Rate Difference: 1.00\n",
      "False Positive Rate Difference: 0.48\n",
      "Selection Rate Difference: 0.58\n",
      "\n",
      "Fairness metrics for total_adult_crimes_bin:\n",
      "Disparate Impact Ratio: 0.23\n",
      "Equalized Odds Ratio: 0.12\n",
      "True Positive Rate Difference: 0.66\n",
      "False Positive Rate Difference: 0.88\n",
      "Selection Rate Difference: 0.77\n",
      "\n",
      "Disparate Impact Ratios by Sex:\n",
      "Male: 1.09\n",
      "Female: 0.65\n",
      "\n",
      "Disparate Impact Ratios by Race:\n",
      "African-American: 1.28\n",
      "Asian: 0.34\n",
      "Caucasian: 0.69\n",
      "Other: 0.70\n",
      "Hispanic: 0.76\n",
      "Native American: 1.51\n",
      "\n",
      "Disparate Impact Ratios by Total_adult_crimes_bin:\n",
      "10+: 2.02\n",
      "3-4: 1.44\n",
      "<0: 0.46\n",
      "1-2: 1.24\n",
      "0: 0.50\n",
      "5-9: 1.88\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from fairlearn.metrics import (\n",
    "    demographic_parity_ratio, equalized_odds_ratio,\n",
    "    true_positive_rate_difference, false_positive_rate_difference,\n",
    "    selection_rate_difference\n",
    ")\n",
    "\n",
    "# Define preprocess_data function to include binning for total_adult_crimes\n",
    "def preprocess_data(df):\n",
    "    df['dob'] = pd.to_datetime(df['dob'])\n",
    "    df['c_offense_date'] = pd.to_datetime(df['c_offense_date'])\n",
    "    df['c_arrest_date'] = pd.to_datetime(df['c_arrest_date'])\n",
    "    df['c_jail_in'] = pd.to_datetime(df['c_jail_in'])\n",
    "\n",
    "    df['unified_date'] = df['c_arrest_date'].combine_first(df['c_offense_date'])\n",
    "\n",
    "    df['age_birth'] = (pd.to_datetime('today') - df['dob']).dt.days // 365\n",
    "    df['age_at_unified_date'] = (df['unified_date'] - df['dob']).dt.days // 365\n",
    "    \n",
    "    avg_time_offense_arrest = (df['c_arrest_date'] - df['c_offense_date']).dt.days.mean()\n",
    "    avg_time_since_jail_in = (pd.to_datetime('today') - df['c_jail_in']).dt.days.mean()\n",
    "    avg_time_to_jail = (df['c_jail_in'] - df['unified_date']).dt.days.mean()\n",
    "\n",
    "    df['time_offense_arrest'] = (df['c_arrest_date'] - df['c_offense_date']).dt.days.fillna(avg_time_offense_arrest)\n",
    "    df['time_since_jail_in'] = (pd.to_datetime('today') - df['c_jail_in']).dt.days.fillna(avg_time_since_jail_in)\n",
    "    df['time_to_jail'] = (df['c_jail_in'] - df['unified_date']).dt.days.fillna(avg_time_to_jail)\n",
    "    \n",
    "    df['total_juv_crimes'] = df['juv_fel_count'] + df['juv_misd_count'] + df['juv_other_count']\n",
    "    df['total_adult_crimes'] = df['priors_count'] - df['total_juv_crimes']\n",
    "    \n",
    "    # Apply frequency encoding\n",
    "    df['c_charge_desc_freq'] = df['c_charge_desc'].map(df['c_charge_desc'].value_counts(normalize=True))\n",
    "\n",
    "    # Create bins for total_adult_crimes\n",
    "    bins = [-np.inf, 0, 1, 3, 5, 10, np.inf]\n",
    "    labels = ['<0', '0', '1-2', '3-4', '5-9', '10+']\n",
    "    df['total_adult_crimes_bin'] = pd.cut(df['total_adult_crimes'], bins=bins, labels=labels)\n",
    "\n",
    "    return df\n",
    "\n",
    "# Assuming df is already loaded and preprocessed\n",
    "# Apply preprocessing to the entire dataset\n",
    "df = preprocess_data(df)\n",
    "\n",
    "# Split data into train and test sets\n",
    "df_train, df_test = train_test_split(df, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define features\n",
    "all_features = [\n",
    "    \"sex\", \n",
    "    \"race\", \n",
    "    \"total_adult_crimes_bin\", \n",
    "    \"c_charge_degree\", \n",
    "    \"c_charge_desc_freq\",\n",
    "    \"age_at_unified_date\", \n",
    "    \"total_juv_crimes\",\n",
    "    \"offense_month\", \n",
    "    \"offense_day_of_week\", \n",
    "    \"arrest_month\", \n",
    "    \"arrest_day_of_week\"\n",
    "]\n",
    "\n",
    "numerical_features = [\n",
    "    \"total_juv_crimes\",\n",
    "    \"offense_month\", \n",
    "    \"offense_day_of_week\", \n",
    "    \"arrest_month\", \n",
    "    \"arrest_day_of_week\",\n",
    "    \"age_at_unified_date\", \n",
    "    \"c_charge_desc_freq\"\n",
    "]\n",
    "\n",
    "categorical_features = [\n",
    "    \"sex\", \n",
    "    \"race\", \n",
    "    \"total_adult_crimes_bin\", \n",
    "    \"c_charge_degree\"\n",
    "]\n",
    "\n",
    "target = 'is_recid'\n",
    "\n",
    "# Define preprocessing pipelines\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value='missing_value')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numerical_features),\n",
    "        ('cat', categorical_transformer, categorical_features)\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Use the best model parameters found earlier\n",
    "best_model_params = {\n",
    "    'learning_rate': 0.01,\n",
    "    'max_depth': 3,\n",
    "    'n_estimators': 300,\n",
    "    'subsample': 0.8,\n",
    "    'random_state': 42\n",
    "}\n",
    "\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', XGBClassifier(**best_model_params))\n",
    "])\n",
    "\n",
    "# Fit the model without sample weights first to get preprocessed data for SMOTE\n",
    "X_train = df_train[all_features]\n",
    "y_train = df_train[target]\n",
    "\n",
    "# Apply preprocessing to the training data before SMOTE\n",
    "X_train_transformed = preprocessor.fit_transform(X_train)\n",
    "\n",
    "# Apply SMOTE to address class imbalance\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train_transformed, y_train)\n",
    "\n",
    "# Fit the model using resampled data\n",
    "pipeline.named_steps['classifier'].fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# Transform the test data\n",
    "X_test_transformed = preprocessor.transform(df_test[all_features])\n",
    "y_test = df_test[target]\n",
    "\n",
    "# Predictions\n",
    "y_pred = pipeline.named_steps['classifier'].predict(X_test_transformed)\n",
    "y_proba = pipeline.named_steps['classifier'].predict_proba(X_test_transformed)[:, 1]\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "roc_auc = roc_auc_score(y_test, y_proba)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Print evaluation metrics\n",
    "print(f'Accuracy: {accuracy:.2f}')\n",
    "print(f'Precision: {precision:.2f}')\n",
    "print(f'Recall: {recall:.2f}')\n",
    "print(f'F1-Score: {f1:.2f}')\n",
    "print(f'ROC-AUC: {roc_auc:.2f}')\n",
    "print(f'Confusion Matrix:\\n{conf_matrix}')\n",
    "\n",
    "# Fairness metrics\n",
    "for feature in ['sex', 'race', 'total_adult_crimes_bin']:\n",
    "    print(f\"\\nFairness metrics for {feature}:\")\n",
    "    disparate_impact = demographic_parity_ratio(y_true=y_test, y_pred=y_pred, sensitive_features=X_test[feature])\n",
    "    equalized_odds = equalized_odds_ratio(y_true=y_test, y_pred=y_pred, sensitive_features=X_test[feature])\n",
    "    tpr_diff = true_positive_rate_difference(y_true=y_test, y_pred=y_pred, sensitive_features=X_test[feature])\n",
    "    fpr_diff = false_positive_rate_difference(y_true=y_test, y_pred=y_pred, sensitive_features=X_test[feature])\n",
    "    selection_rate_diff = selection_rate_difference(y_true=y_test, y_pred=y_pred, sensitive_features=X_test[feature])\n",
    "    print(f\"Disparate Impact Ratio: {disparate_impact:.2f}\")\n",
    "    print(f\"Equalized Odds Ratio: {equalized_odds:.2f}\")\n",
    "    print(f\"True Positive Rate Difference: {tpr_diff:.2f}\")\n",
    "    print(f\"False Positive Rate Difference: {fpr_diff:.2f}\")\n",
    "    print(f\"Selection Rate Difference: {selection_rate_diff:.2f}\")\n",
    "\n",
    "# Disparate impact ratios by group for each sensitive feature\n",
    "def calculate_disparate_impact(y_true, y_pred, X_test, column):\n",
    "    disparate_impact_ratios = {}\n",
    "    overall_favorable_outcomes = y_pred.mean()\n",
    "    for value in X_test[column].unique():\n",
    "        mask = X_test[column] == value\n",
    "        favorable_outcomes = y_pred[mask].mean()\n",
    "        if overall_favorable_outcomes == 0:\n",
    "            disparate_impact_ratios[value] = np.nan\n",
    "        else:\n",
    "            disparate_impact_ratios[value] = favorable_outcomes / overall_favorable_outcomes\n",
    "    return disparate_impact_ratios\n",
    "\n",
    "for feature in ['sex', 'race', 'total_adult_crimes_bin']:\n",
    "    disparate_impact_by_group = calculate_disparate_impact(y_test, y_pred, X_test, feature)\n",
    "    print(f\"\\nDisparate Impact Ratios by {feature.capitalize()}:\")\n",
    "    for group, ratio in disparate_impact_by_group.items():\n",
    "        print(f\"{group}: {ratio:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6f06a1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "##ANOTHER TRIAL:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "cb23b622",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.66\n",
      "Precision: 0.63\n",
      "Recall: 0.62\n",
      "F1-Score: 0.62\n",
      "ROC-AUC: 0.73\n",
      "Confusion Matrix:\n",
      "[[449 195]\n",
      " [201 326]]\n",
      "\n",
      "Fairness metrics for sex:\n",
      "Disparate Impact Ratio: 0.61\n",
      "Equalized Odds Ratio: 0.52\n",
      "True Positive Rate Difference: 0.12\n",
      "False Positive Rate Difference: 0.17\n",
      "Selection Rate Difference: 0.19\n",
      "\n",
      "Fairness metrics for race:\n",
      "Disparate Impact Ratio: 0.41\n",
      "Equalized Odds Ratio: 0.00\n",
      "True Positive Rate Difference: 1.00\n",
      "False Positive Rate Difference: 0.60\n",
      "Selection Rate Difference: 0.44\n",
      "\n",
      "Fairness metrics for total_adult_crimes_bin:\n",
      "Disparate Impact Ratio: 0.22\n",
      "Equalized Odds Ratio: 0.12\n",
      "True Positive Rate Difference: 0.54\n",
      "False Positive Rate Difference: 0.88\n",
      "Selection Rate Difference: 0.73\n",
      "\n",
      "Disparate Impact Ratios by Sex:\n",
      "Male: 1.09\n",
      "Female: 0.67\n",
      "\n",
      "Disparate Impact Ratios by Race:\n",
      "African-American: 1.24\n",
      "Asian: 1.12\n",
      "Caucasian: 0.72\n",
      "Other: 0.69\n",
      "Hispanic: 0.82\n",
      "Native American: 1.69\n",
      "\n",
      "Disparate Impact Ratios by Total_adult_crimes_bin:\n",
      "10+: 2.10\n",
      "3-4: 1.55\n",
      "<0: 0.46\n",
      "1-2: 1.21\n",
      "0: 0.55\n",
      "5-9: 1.72\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, PolynomialFeatures\n",
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier, VotingClassifier\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from fairlearn.metrics import (\n",
    "    demographic_parity_ratio, equalized_odds_ratio,\n",
    "    true_positive_rate_difference, false_positive_rate_difference,\n",
    "    selection_rate_difference\n",
    ")\n",
    "\n",
    "# Define preprocess_data function to include binning for total_adult_crimes\n",
    "def preprocess_data(df):\n",
    "    df['dob'] = pd.to_datetime(df['dob'])\n",
    "    df['c_offense_date'] = pd.to_datetime(df['c_offense_date'])\n",
    "    df['c_arrest_date'] = pd.to_datetime(df['c_arrest_date'])\n",
    "    df['c_jail_in'] = pd.to_datetime(df['c_jail_in'])\n",
    "\n",
    "    df['unified_date'] = df['c_arrest_date'].combine_first(df['c_offense_date'])\n",
    "\n",
    "    df['age_birth'] = (pd.to_datetime('today') - df['dob']).dt.days // 365\n",
    "    df['age_at_unified_date'] = (df['unified_date'] - df['dob']).dt.days // 365\n",
    "    \n",
    "    avg_time_offense_arrest = (df['c_arrest_date'] - df['c_offense_date']).dt.days.mean()\n",
    "    avg_time_since_jail_in = (pd.to_datetime('today') - df['c_jail_in']).dt.days.mean()\n",
    "    avg_time_to_jail = (df['c_jail_in'] - df['unified_date']).dt.days.mean()\n",
    "\n",
    "    df['time_offense_arrest'] = (df['c_arrest_date'] - df['c_offense_date']).dt.days.fillna(avg_time_offense_arrest)\n",
    "    df['time_since_jail_in'] = (pd.to_datetime('today') - df['c_jail_in']).dt.days.fillna(avg_time_since_jail_in)\n",
    "    df['time_to_jail'] = (df['c_jail_in'] - df['unified_date']).dt.days.fillna(avg_time_to_jail)\n",
    "    \n",
    "    df['total_juv_crimes'] = df['juv_fel_count'] + df['juv_misd_count'] + df['juv_other_count']\n",
    "    df['total_adult_crimes'] = df['priors_count'] - df['total_juv_crimes']\n",
    "    \n",
    "    # Apply frequency encoding\n",
    "    df['c_charge_desc_freq'] = df['c_charge_desc'].map(df['c_charge_desc'].value_counts(normalize=True))\n",
    "\n",
    "    # Create bins for total_adult_crimes\n",
    "    bins = [-np.inf, 0, 1, 3, 5, 10, np.inf]\n",
    "    labels = ['<0', '0', '1-2', '3-4', '5-9', '10+']\n",
    "    df['total_adult_crimes_bin'] = pd.cut(df['total_adult_crimes'], bins=bins, labels=labels)\n",
    "\n",
    "    return df\n",
    "\n",
    "# Assuming df is already loaded and preprocessed\n",
    "# Apply preprocessing to the entire dataset\n",
    "df = preprocess_data(df)\n",
    "\n",
    "# Split data into train and test sets\n",
    "df_train, df_test = train_test_split(df, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define features\n",
    "all_features = [\n",
    "    \"sex\", \n",
    "    \"race\", \n",
    "    \"total_adult_crimes_bin\", \n",
    "    \"c_charge_degree\", \n",
    "    \"c_charge_desc_freq\",\n",
    "    \"age_at_unified_date\", \n",
    "    \"total_juv_crimes\",\n",
    "    \"offense_month\", \n",
    "    \"offense_day_of_week\", \n",
    "    \"arrest_month\", \n",
    "    \"arrest_day_of_week\"\n",
    "]\n",
    "\n",
    "numerical_features = [\n",
    "    \"total_juv_crimes\",\n",
    "    \"offense_month\", \n",
    "    \"offense_day_of_week\", \n",
    "    \"arrest_month\", \n",
    "    \"arrest_day_of_week\",\n",
    "    \"age_at_unified_date\", \n",
    "    \"c_charge_desc_freq\"\n",
    "]\n",
    "\n",
    "categorical_features = [\n",
    "    \"sex\", \n",
    "    \"race\", \n",
    "    \"total_adult_crimes_bin\", \n",
    "    \"c_charge_degree\"\n",
    "]\n",
    "\n",
    "target = 'is_recid'\n",
    "\n",
    "# Define preprocessing pipelines\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('poly', PolynomialFeatures(degree=2, include_bias=False))\n",
    "])\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value='missing_value')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numerical_features),\n",
    "        ('cat', categorical_transformer, categorical_features)\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Define ensemble model\n",
    "rf_model = RandomForestClassifier(random_state=42)\n",
    "gb_model = GradientBoostingClassifier(random_state=42)\n",
    "voting_model = VotingClassifier(estimators=[('rf', rf_model), ('gb', gb_model)], voting='soft')\n",
    "\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', voting_model)\n",
    "])\n",
    "\n",
    "# Apply preprocessing to the training data before SMOTE\n",
    "X_train = df_train[all_features]\n",
    "y_train = df_train[target]\n",
    "X_train_transformed = preprocessor.fit_transform(X_train)\n",
    "\n",
    "# Apply SMOTE to address class imbalance\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train_transformed, y_train)\n",
    "\n",
    "# Fit the model using resampled data\n",
    "pipeline.named_steps['classifier'].fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# Transform the test data\n",
    "X_test_transformed = preprocessor.transform(df_test[all_features])\n",
    "y_test = df_test[target]\n",
    "\n",
    "# Predictions\n",
    "y_pred = pipeline.named_steps['classifier'].predict(X_test_transformed)\n",
    "y_proba = pipeline.named_steps['classifier'].predict_proba(X_test_transformed)[:, 1]\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "roc_auc = roc_auc_score(y_test, y_proba)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Print evaluation metrics\n",
    "print(f'Accuracy: {accuracy:.2f}')\n",
    "print(f'Precision: {precision:.2f}')\n",
    "print(f'Recall: {recall:.2f}')\n",
    "print(f'F1-Score: {f1:.2f}')\n",
    "print(f'ROC-AUC: {roc_auc:.2f}')\n",
    "print(f'Confusion Matrix:\\n{conf_matrix}')\n",
    "\n",
    "# Fairness metrics\n",
    "for feature in ['sex', 'race', 'total_adult_crimes_bin']:\n",
    "    print(f\"\\nFairness metrics for {feature}:\")\n",
    "    disparate_impact = demographic_parity_ratio(y_true=y_test, y_pred=y_pred, sensitive_features=X_test[feature])\n",
    "    equalized_odds = equalized_odds_ratio(y_true=y_test, y_pred=y_pred, sensitive_features=X_test[feature])\n",
    "    tpr_diff = true_positive_rate_difference(y_true=y_test, y_pred=y_pred, sensitive_features=X_test[feature])\n",
    "    fpr_diff = false_positive_rate_difference(y_true=y_test, y_pred=y_pred, sensitive_features=X_test[feature])\n",
    "    selection_rate_diff = selection_rate_difference(y_true=y_test, y_pred=y_pred, sensitive_features=X_test[feature])\n",
    "    print(f\"Disparate Impact Ratio: {disparate_impact:.2f}\")\n",
    "    print(f\"Equalized Odds Ratio: {equalized_odds:.2f}\")\n",
    "    print(f\"True Positive Rate Difference: {tpr_diff:.2f}\")\n",
    "    print(f\"False Positive Rate Difference: {fpr_diff:.2f}\")\n",
    "    print(f\"Selection Rate Difference: {selection_rate_diff:.2f}\")\n",
    "\n",
    "# Disparate impact ratios by group for each sensitive feature\n",
    "def calculate_disparate_impact(y_true, y_pred, X_test, column):\n",
    "    disparate_impact_ratios = {}\n",
    "    overall_favorable_outcomes = y_pred.mean()\n",
    "    for value in X_test[column].unique():\n",
    "        mask = X_test[column] == value\n",
    "        favorable_outcomes = y_pred[mask].mean()\n",
    "        if overall_favorable_outcomes == 0:\n",
    "            disparate_impact_ratios[value] = np.nan\n",
    "        else:\n",
    "            disparate_impact_ratios[value] = favorable_outcomes / overall_favorable_outcomes\n",
    "    return disparate_impact_ratios\n",
    "\n",
    "for feature in ['sex', 'race', 'total_adult_crimes_bin']:\n",
    "    disparate_impact_by_group = calculate_disparate_impact(y_test, y_pred, X_test, feature)\n",
    "    print(f\"\\nDisparate Impact Ratios by {feature.capitalize()}:\")\n",
    "    for group, ratio in disparate_impact_by_group.items():\n",
    "        print(f\"{group}: {ratio:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd885fbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "##OTHER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "3cc59a0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.67\n",
      "Precision: 0.64\n",
      "Recall: 0.65\n",
      "F1-Score: 0.64\n",
      "ROC-AUC: 0.73\n",
      "Confusion Matrix:\n",
      "[[447 197]\n",
      " [184 343]]\n",
      "\n",
      "Fairness metrics for sex:\n",
      "Disparate Impact Ratio: 0.47\n",
      "Equalized Odds Ratio: 0.33\n",
      "True Positive Rate Difference: 0.21\n",
      "False Positive Rate Difference: 0.25\n",
      "Selection Rate Difference: 0.28\n",
      "\n",
      "Fairness metrics for race:\n",
      "Disparate Impact Ratio: 0.56\n",
      "Equalized Odds Ratio: 0.00\n",
      "True Positive Rate Difference: 0.75\n",
      "False Positive Rate Difference: 0.41\n",
      "Selection Rate Difference: 0.25\n",
      "\n",
      "Fairness metrics for total_adult_crimes_bin:\n",
      "Disparate Impact Ratio: 0.22\n",
      "Equalized Odds Ratio: 0.12\n",
      "True Positive Rate Difference: 0.52\n",
      "False Positive Rate Difference: 0.85\n",
      "Selection Rate Difference: 0.73\n",
      "\n",
      "Disparate Impact Ratios by Sex:\n",
      "Male: 1.12\n",
      "Female: 0.53\n",
      "\n",
      "Disparate Impact Ratios by Race:\n",
      "African-American: 1.26\n",
      "Asian: 0.72\n",
      "Caucasian: 0.72\n",
      "Other: 0.71\n",
      "Hispanic: 0.77\n",
      "Native American: 1.08\n",
      "\n",
      "Disparate Impact Ratios by Total_adult_crimes_bin:\n",
      "10+: 2.02\n",
      "3-4: 1.55\n",
      "<0: 0.45\n",
      "1-2: 1.21\n",
      "0: 0.59\n",
      "5-9: 1.74\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier, StackingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from fairlearn.metrics import (\n",
    "    demographic_parity_ratio, equalized_odds_ratio,\n",
    "    true_positive_rate_difference, false_positive_rate_difference,\n",
    "    selection_rate_difference\n",
    ")\n",
    "\n",
    "# Define preprocess_data function to include binning for total_adult_crimes\n",
    "def preprocess_data(df):\n",
    "    df['dob'] = pd.to_datetime(df['dob'])\n",
    "    df['c_offense_date'] = pd.to_datetime(df['c_offense_date'])\n",
    "    df['c_arrest_date'] = pd.to_datetime(df['c_arrest_date'])\n",
    "    df['c_jail_in'] = pd.to_datetime(df['c_jail_in'])\n",
    "\n",
    "    df['unified_date'] = df['c_arrest_date'].combine_first(df['c_offense_date'])\n",
    "\n",
    "    df['age_birth'] = (pd.to_datetime('today') - df['dob']).dt.days // 365\n",
    "    df['age_at_unified_date'] = (df['unified_date'] - df['dob']).dt.days // 365\n",
    "    \n",
    "    avg_time_offense_arrest = (df['c_arrest_date'] - df['c_offense_date']).dt.days.mean()\n",
    "    avg_time_since_jail_in = (pd.to_datetime('today') - df['c_jail_in']).dt.days.mean()\n",
    "    avg_time_to_jail = (df['c_jail_in'] - df['unified_date']).dt.days.mean()\n",
    "\n",
    "    df['time_offense_arrest'] = (df['c_arrest_date'] - df['c_offense_date']).dt.days.fillna(avg_time_offense_arrest)\n",
    "    df['time_since_jail_in'] = (pd.to_datetime('today') - df['c_jail_in']).dt.days.fillna(avg_time_since_jail_in)\n",
    "    df['time_to_jail'] = (df['c_jail_in'] - df['unified_date']).dt.days.fillna(avg_time_to_jail)\n",
    "    \n",
    "    df['total_juv_crimes'] = df['juv_fel_count'] + df['juv_misd_count'] + df['juv_other_count']\n",
    "    df['total_adult_crimes'] = df['priors_count'] - df['total_juv_crimes']\n",
    "    \n",
    "    # Apply frequency encoding\n",
    "    df['c_charge_desc_freq'] = df['c_charge_desc'].map(df['c_charge_desc'].value_counts(normalize=True))\n",
    "\n",
    "    # Create bins for total_adult_crimes\n",
    "    bins = [-np.inf, 0, 1, 3, 5, 10, np.inf]\n",
    "    labels = ['<0', '0', '1-2', '3-4', '5-9', '10+']\n",
    "    df['total_adult_crimes_bin'] = pd.cut(df['total_adult_crimes'], bins=bins, labels=labels)\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Assuming df is already loaded and preprocessed\n",
    "# Apply preprocessing to the entire dataset\n",
    "df = preprocess_data(df)\n",
    "\n",
    "# Split data into train and test sets\n",
    "df_train, df_test = train_test_split(df, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define features\n",
    "all_features = [\n",
    "    \"sex\", \n",
    "    \"race\", \n",
    "    \"total_adult_crimes_bin\", \n",
    "    \"c_charge_degree\", \n",
    "    \"c_charge_desc_freq\",\n",
    "    \"age_at_unified_date\", \n",
    "    \"total_juv_crimes\",\n",
    "    \"offense_month\", \n",
    "    \"offense_day_of_week\", \n",
    "    \"arrest_month\", \n",
    "    \"arrest_day_of_week\"\n",
    "]\n",
    "\n",
    "numerical_features = [\n",
    "    \"total_juv_crimes\",\n",
    "    \"offense_month\", \n",
    "    \"offense_day_of_week\", \n",
    "    \"arrest_month\", \n",
    "    \"arrest_day_of_week\",\n",
    "    \"age_at_unified_date\", \n",
    "    \"c_charge_desc_freq\"\n",
    "]\n",
    "\n",
    "categorical_features = [\n",
    "    \"sex\", \n",
    "    \"race\", \n",
    "    \"total_adult_crimes_bin\", \n",
    "    \"c_charge_degree\"\n",
    "]\n",
    "\n",
    "target = 'is_recid'\n",
    "\n",
    "# Define preprocessing pipelines\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value='missing_value')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numerical_features),\n",
    "        ('cat', categorical_transformer, categorical_features)\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Define base models for stacking\n",
    "base_models = [\n",
    "    ('rf', RandomForestClassifier(n_estimators=100, random_state=42)),\n",
    "    ('gb', GradientBoostingClassifier(n_estimators=100, random_state=42))\n",
    "]\n",
    "\n",
    "# Define stacking ensemble\n",
    "stacking_model = StackingClassifier(\n",
    "    estimators=base_models,\n",
    "    final_estimator=LogisticRegression(),\n",
    "    cv=5\n",
    ")\n",
    "\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', stacking_model)\n",
    "])\n",
    "\n",
    "# Apply preprocessing to the training data before SMOTE\n",
    "X_train = df_train[all_features]\n",
    "y_train = df_train[target]\n",
    "X_train_transformed = preprocessor.fit_transform(X_train)\n",
    "\n",
    "# Apply SMOTE to address class imbalance\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train_transformed, y_train)\n",
    "\n",
    "# Fit the model using resampled data\n",
    "pipeline.named_steps['classifier'].fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# Transform the test data\n",
    "X_test_transformed = preprocessor.transform(df_test[all_features])\n",
    "y_test = df_test[target]\n",
    "\n",
    "# Predictions\n",
    "y_pred = pipeline.named_steps['classifier'].predict(X_test_transformed)\n",
    "y_proba = pipeline.named_steps['classifier'].predict_proba(X_test_transformed)[:, 1]\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "roc_auc = roc_auc_score(y_test, y_proba)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Print evaluation metrics\n",
    "print(f'Accuracy: {accuracy:.2f}')\n",
    "print(f'Precision: {precision:.2f}')\n",
    "print(f'Recall: {recall:.2f}')\n",
    "print(f'F1-Score: {f1:.2f}')\n",
    "print(f'ROC-AUC: {roc_auc:.2f}')\n",
    "print(f'Confusion Matrix:\\n{conf_matrix}')\n",
    "\n",
    "# Fairness metrics\n",
    "for feature in ['sex', 'race', 'total_adult_crimes_bin']:\n",
    "    print(f\"\\nFairness metrics for {feature}:\")\n",
    "    disparate_impact = demographic_parity_ratio(y_true=y_test, y_pred=y_pred, sensitive_features=X_test[feature])\n",
    "    equalized_odds = equalized_odds_ratio(y_true=y_test, y_pred=y_pred, sensitive_features=X_test[feature])\n",
    "    tpr_diff = true_positive_rate_difference(y_true=y_test, y_pred=y_pred, sensitive_features=X_test[feature])\n",
    "    fpr_diff = false_positive_rate_difference(y_true=y_test, y_pred=y_pred, sensitive_features=X_test[feature])\n",
    "    selection_rate_diff = selection_rate_difference(y_true=y_test, y_pred=y_pred, sensitive_features=X_test[feature])\n",
    "    print(f\"Disparate Impact Ratio: {disparate_impact:.2f}\")\n",
    "    print(f\"Equalized Odds Ratio: {equalized_odds:.2f}\")\n",
    "    print(f\"True Positive Rate Difference: {tpr_diff:.2f}\")\n",
    "    print(f\"False Positive Rate Difference: {fpr_diff:.2f}\")\n",
    "    print(f\"Selection Rate Difference: {selection_rate_diff:.2f}\")\n",
    "\n",
    "# Disparate impact ratios by group for each sensitive feature\n",
    "def calculate_disparate_impact(y_true, y_pred, X_test, column):\n",
    "    disparate_impact_ratios = {}\n",
    "    overall_favorable_outcomes = y_pred.mean()\n",
    "    for value in X_test[column].unique():\n",
    "        mask = X_test[column] == value\n",
    "        favorable_outcomes = y_pred[mask].mean()\n",
    "        if overall_favorable_outcomes == 0:\n",
    "            disparate_impact_ratios[value] = np.nan\n",
    "        else:\n",
    "            disparate_impact_ratios[value] = favorable_outcomes / overall_favorable_outcomes\n",
    "    return disparate_impact_ratios\n",
    "\n",
    "for feature in ['sex', 'race', 'total_adult_crimes_bin']:\n",
    "    disparate_impact_by_group = calculate_disparate_impact(y_test, y_pred, X_test, feature)\n",
    "    print(f\"\\nDisparate Impact Ratios by {feature.capitalize()}:\")\n",
    "    for group, ratio in disparate_impact_by_group.items():\n",
    "        print(f\"{group}: {ratio:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "ef702bac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/teresaramoos/.local/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [21:28:44] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/teresaramoos/.local/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [21:28:44] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/teresaramoos/.local/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [21:28:44] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/teresaramoos/.local/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [21:28:44] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/teresaramoos/.local/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [21:28:44] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/teresaramoos/.local/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [21:28:47] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/teresaramoos/.local/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [21:28:47] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/teresaramoos/.local/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [21:28:52] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/teresaramoos/.local/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [21:28:52] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/teresaramoos/.local/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [21:28:52] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/teresaramoos/.local/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [21:28:55] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/teresaramoos/.local/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [21:28:55] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/teresaramoos/.local/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [21:28:55] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/teresaramoos/.local/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [21:28:55] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/teresaramoos/.local/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [21:28:55] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/teresaramoos/.local/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [21:28:56] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/teresaramoos/.local/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [21:28:56] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/teresaramoos/.local/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [21:28:56] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/teresaramoos/.local/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [21:28:56] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/teresaramoos/.local/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [21:28:56] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/teresaramoos/.local/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [21:28:59] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/teresaramoos/.local/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [21:28:59] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/teresaramoos/.local/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [21:28:59] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/teresaramoos/.local/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [21:28:59] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/teresaramoos/.local/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [21:28:59] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/teresaramoos/.local/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [21:29:02] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/teresaramoos/.local/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [21:29:02] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/teresaramoos/.local/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [21:29:02] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/teresaramoos/.local/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [21:29:02] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/teresaramoos/.local/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [21:29:02] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/teresaramoos/.local/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [21:29:02] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/teresaramoos/.local/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [21:29:02] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/teresaramoos/.local/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [21:29:02] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/teresaramoos/.local/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [21:29:02] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/teresaramoos/.local/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [21:29:02] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/teresaramoos/.local/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [21:29:04] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/teresaramoos/.local/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [21:29:04] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/teresaramoos/.local/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [21:29:04] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/teresaramoos/.local/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [21:29:04] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/teresaramoos/.local/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [21:29:04] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/teresaramoos/.local/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [21:29:06] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/teresaramoos/.local/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [21:29:06] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/teresaramoos/.local/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [21:29:06] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/teresaramoos/.local/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [21:29:06] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/teresaramoos/.local/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [21:29:06] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/teresaramoos/.local/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [21:29:09] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/teresaramoos/.local/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [21:29:09] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/teresaramoos/.local/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [21:29:09] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/teresaramoos/.local/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [21:29:09] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/teresaramoos/.local/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [21:29:09] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/teresaramoos/.local/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [21:29:13] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/teresaramoos/.local/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [21:29:13] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/teresaramoos/.local/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [21:29:13] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/teresaramoos/.local/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [21:29:13] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/teresaramoos/.local/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [21:29:13] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/teresaramoos/.local/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [21:29:16] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/teresaramoos/.local/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [21:29:16] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/teresaramoos/.local/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [21:29:16] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/teresaramoos/.local/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [21:29:16] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/teresaramoos/.local/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [21:29:16] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/teresaramoos/.local/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [21:29:18] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/teresaramoos/.local/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [21:29:18] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/teresaramoos/.local/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [21:29:18] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/teresaramoos/.local/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [21:29:18] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/teresaramoos/.local/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [21:29:18] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/teresaramoos/.local/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [21:29:22] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/teresaramoos/.local/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [21:29:22] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/teresaramoos/.local/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [21:29:22] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/teresaramoos/.local/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [21:29:22] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/teresaramoos/.local/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [21:29:22] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/teresaramoos/.local/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [21:29:24] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/teresaramoos/.local/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [21:29:24] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/teresaramoos/.local/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [21:29:24] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/teresaramoos/.local/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [21:29:24] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/teresaramoos/.local/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [21:29:24] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/teresaramoos/.local/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [21:29:28] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/teresaramoos/.local/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [21:29:28] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/teresaramoos/.local/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [21:29:28] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/teresaramoos/.local/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [21:29:28] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/teresaramoos/.local/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [21:29:28] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/teresaramoos/.local/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [21:29:31] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/teresaramoos/.local/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [21:29:31] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/teresaramoos/.local/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [21:29:31] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/teresaramoos/.local/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [21:29:31] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/teresaramoos/.local/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [21:29:31] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/teresaramoos/.local/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [21:29:33] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/teresaramoos/.local/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [21:29:33] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/teresaramoos/.local/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [21:29:33] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/teresaramoos/.local/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [21:29:33] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/teresaramoos/.local/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [21:29:33] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/teresaramoos/.local/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [21:29:45] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/teresaramoos/.local/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [21:29:45] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/teresaramoos/.local/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [21:29:45] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/teresaramoos/.local/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [21:29:45] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/teresaramoos/.local/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [21:29:45] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/teresaramoos/.local/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [21:29:49] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/teresaramoos/.local/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [21:29:50] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/teresaramoos/.local/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [21:29:50] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/teresaramoos/.local/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [21:29:50] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/teresaramoos/.local/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [21:29:50] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/teresaramoos/.local/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [21:29:53] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/teresaramoos/.local/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [21:29:53] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/teresaramoos/.local/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [21:29:53] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/teresaramoos/.local/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [21:29:53] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/teresaramoos/.local/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [21:29:53] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/teresaramoos/.local/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [21:30:01] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/teresaramoos/.local/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [21:30:01] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/teresaramoos/.local/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [21:30:01] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/teresaramoos/.local/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [21:30:01] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/teresaramoos/.local/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [21:30:01] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/teresaramoos/.local/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [21:30:03] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/teresaramoos/.local/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [21:30:03] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/teresaramoos/.local/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [21:30:03] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/teresaramoos/.local/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [21:30:03] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/teresaramoos/.local/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [21:30:03] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/teresaramoos/.local/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [21:30:06] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/teresaramoos/.local/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [21:30:06] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/teresaramoos/.local/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [21:30:06] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/teresaramoos/.local/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [21:30:06] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/teresaramoos/.local/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [21:30:06] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/teresaramoos/.local/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [21:30:14] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/teresaramoos/.local/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [21:30:14] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/teresaramoos/.local/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [21:30:14] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/teresaramoos/.local/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [21:30:14] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/teresaramoos/.local/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [21:30:14] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/teresaramoos/.local/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [21:30:17] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/teresaramoos/.local/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [21:30:17] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/teresaramoos/.local/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [21:30:17] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/teresaramoos/.local/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [21:30:17] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/teresaramoos/.local/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [21:30:17] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/teresaramoos/.local/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [21:30:20] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/teresaramoos/.local/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [21:30:20] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/teresaramoos/.local/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [21:30:20] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/teresaramoos/.local/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [21:30:20] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/teresaramoos/.local/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [21:30:20] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/teresaramoos/.local/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [21:30:24] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/teresaramoos/.local/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [21:30:24] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/teresaramoos/.local/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [21:30:24] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/teresaramoos/.local/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [21:30:24] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/teresaramoos/.local/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [21:30:24] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/teresaramoos/.local/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [21:30:27] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/teresaramoos/.local/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [21:30:27] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/teresaramoos/.local/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [21:30:27] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/teresaramoos/.local/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [21:30:27] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/teresaramoos/.local/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [21:30:27] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/teresaramoos/.local/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [21:30:29] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/teresaramoos/.local/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [21:30:29] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/teresaramoos/.local/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [21:30:29] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/teresaramoos/.local/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [21:30:29] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/teresaramoos/.local/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [21:30:29] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/teresaramoos/.local/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [21:30:32] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/teresaramoos/.local/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [21:30:32] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/teresaramoos/.local/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [21:30:32] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/teresaramoos/.local/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [21:30:32] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/teresaramoos/.local/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [21:30:32] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/teresaramoos/.local/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [21:30:37] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/teresaramoos/.local/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [21:30:37] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/teresaramoos/.local/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [21:30:37] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/teresaramoos/.local/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [21:30:37] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/teresaramoos/.local/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [21:30:37] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/teresaramoos/.local/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [21:30:38] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.67\n",
      "Precision: 0.63\n",
      "Recall: 0.65\n",
      "F1-Score: 0.64\n",
      "ROC-AUC: 0.74\n",
      "Confusion Matrix:\n",
      "[[445 199]\n",
      " [184 343]]\n",
      "\n",
      "Fairness metrics for sex:\n",
      "Disparate Impact Ratio: 0.48\n",
      "Equalized Odds Ratio: 0.38\n",
      "True Positive Rate Difference: 0.24\n",
      "False Positive Rate Difference: 0.22\n",
      "Selection Rate Difference: 0.27\n",
      "\n",
      "Fairness metrics for race:\n",
      "Disparate Impact Ratio: 0.22\n",
      "Equalized Odds Ratio: 0.00\n",
      "True Positive Rate Difference: 1.00\n",
      "False Positive Rate Difference: 0.42\n",
      "Selection Rate Difference: 0.58\n",
      "\n",
      "Fairness metrics for total_adult_crimes_bin:\n",
      "Disparate Impact Ratio: 0.21\n",
      "Equalized Odds Ratio: 0.10\n",
      "True Positive Rate Difference: 0.56\n",
      "False Positive Rate Difference: 0.86\n",
      "Selection Rate Difference: 0.75\n",
      "\n",
      "Disparate Impact Ratios by Sex:\n",
      "Male: 1.12\n",
      "Female: 0.53\n",
      "\n",
      "Disparate Impact Ratios by Race:\n",
      "African-American: 1.26\n",
      "Asian: 0.36\n",
      "Caucasian: 0.74\n",
      "Other: 0.58\n",
      "Hispanic: 0.73\n",
      "Native American: 1.62\n",
      "\n",
      "Disparate Impact Ratios by Total_adult_crimes_bin:\n",
      "10+: 2.06\n",
      "3-4: 1.53\n",
      "<0: 0.43\n",
      "1-2: 1.14\n",
      "0: 0.57\n",
      "5-9: 1.90\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix\n",
    "from xgboost import XGBClassifier\n",
    "from skopt import BayesSearchCV\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from fairlearn.metrics import (\n",
    "    demographic_parity_ratio, equalized_odds_ratio,\n",
    "    true_positive_rate_difference, false_positive_rate_difference,\n",
    "    selection_rate_difference\n",
    ")\n",
    "\n",
    "# Define preprocess_data function to include binning for total_adult_crimes\n",
    "def preprocess_data(df):\n",
    "    df['dob'] = pd.to_datetime(df['dob'])\n",
    "    df['c_offense_date'] = pd.to_datetime(df['c_offense_date'])\n",
    "    df['c_arrest_date'] = pd.to_datetime(df['c_arrest_date'])\n",
    "    df['c_jail_in'] = pd.to_datetime(df['c_jail_in'])\n",
    "\n",
    "    df['unified_date'] = df['c_arrest_date'].combine_first(df['c_offense_date'])\n",
    "\n",
    "    df['age_birth'] = (pd.to_datetime('today') - df['dob']).dt.days // 365\n",
    "    df['age_at_unified_date'] = (df['unified_date'] - df['dob']).dt.days // 365\n",
    "    \n",
    "    avg_time_offense_arrest = (df['c_arrest_date'] - df['c_offense_date']).dt.days.mean()\n",
    "    avg_time_since_jail_in = (pd.to_datetime('today') - df['c_jail_in']).dt.days.mean()\n",
    "    avg_time_to_jail = (df['c_jail_in'] - df['unified_date']).dt.days.mean()\n",
    "\n",
    "    df['time_offense_arrest'] = (df['c_arrest_date'] - df['c_offense_date']).dt.days.fillna(avg_time_offense_arrest)\n",
    "    df['time_since_jail_in'] = (pd.to_datetime('today') - df['c_jail_in']).dt.days.fillna(avg_time_since_jail_in)\n",
    "    df['time_to_jail'] = (df['c_jail_in'] - df['unified_date']).dt.days.fillna(avg_time_to_jail)\n",
    "    \n",
    "    df['total_juv_crimes'] = df['juv_fel_count'] + df['juv_misd_count'] + df['juv_other_count']\n",
    "    df['total_adult_crimes'] = df['priors_count'] - df['total_juv_crimes']\n",
    "    \n",
    "    # Apply frequency encoding\n",
    "    df['c_charge_desc_freq'] = df['c_charge_desc'].map(df['c_charge_desc'].value_counts(normalize=True))\n",
    "\n",
    "    # Create bins for total_adult_crimes\n",
    "    bins = [-np.inf, 0, 1, 3, 5, 10, np.inf]\n",
    "    labels = ['<0', '0', '1-2', '3-4', '5-9', '10+']\n",
    "    df['total_adult_crimes_bin'] = pd.cut(df['total_adult_crimes'], bins=bins, labels=labels)\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Assuming df is already loaded and preprocessed\n",
    "# Apply preprocessing to the entire dataset\n",
    "df = preprocess_data(df)\n",
    "\n",
    "# Split data into train and test sets\n",
    "df_train, df_test = train_test_split(df, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define features\n",
    "all_features = [\n",
    "    \"sex\", \n",
    "    \"race\", \n",
    "    \"total_adult_crimes_bin\", \n",
    "    \"c_charge_degree\", \n",
    "    \"c_charge_desc_freq\",\n",
    "    \"age_at_unified_date\", \n",
    "    \"total_juv_crimes\",\n",
    "    \"offense_month\", \n",
    "    \"offense_day_of_week\", \n",
    "    \"arrest_month\", \n",
    "    \"arrest_day_of_week\"\n",
    "]\n",
    "\n",
    "numerical_features = [\n",
    "    \"total_juv_crimes\",\n",
    "    \"offense_month\", \n",
    "    \"offense_day_of_week\", \n",
    "    \"arrest_month\", \n",
    "    \"arrest_day_of_week\",\n",
    "    \"age_at_unified_date\", \n",
    "    \"c_charge_desc_freq\"\n",
    "]\n",
    "\n",
    "categorical_features = [\n",
    "    \"sex\", \n",
    "    \"race\", \n",
    "    \"total_adult_crimes_bin\", \n",
    "    \"c_charge_degree\"\n",
    "]\n",
    "\n",
    "target = 'is_recid'\n",
    "\n",
    "# Define preprocessing pipelines\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value='missing_value')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numerical_features),\n",
    "        ('cat', categorical_transformer, categorical_features)\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Define XGBoost model and parameter search space for Bayesian optimization\n",
    "xgb = XGBClassifier(random_state=42, use_label_encoder=False, eval_metric='logloss')\n",
    "\n",
    "param_grid = {\n",
    "    'learning_rate': (0.01, 1.0, 'log-uniform'),\n",
    "    'max_depth': (3, 10),\n",
    "    'n_estimators': (100, 1000),\n",
    "    'subsample': (0.5, 1.0),\n",
    "    'colsample_bytree': (0.5, 1.0)\n",
    "}\n",
    "\n",
    "bayes_cv = BayesSearchCV(\n",
    "    estimator=xgb,\n",
    "    search_spaces=param_grid,\n",
    "    n_iter=32,\n",
    "    cv=5,\n",
    "    random_state=42,\n",
    "    scoring='roc_auc',\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Apply preprocessing to the training data before SMOTE\n",
    "X_train = df_train[all_features]\n",
    "y_train = df_train[target]\n",
    "X_train_transformed = preprocessor.fit_transform(X_train)\n",
    "\n",
    "# Apply SMOTE to address class imbalance\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train_transformed, y_train)\n",
    "\n",
    "# Fit the model using resampled data\n",
    "bayes_cv.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# Transform the test data\n",
    "X_test_transformed = preprocessor.transform(df_test[all_features])\n",
    "y_test = df_test[target]\n",
    "\n",
    "# Predictions\n",
    "y_pred = bayes_cv.predict(X_test_transformed)\n",
    "y_proba = bayes_cv.predict_proba(X_test_transformed)[:, 1]\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "roc_auc = roc_auc_score(y_test, y_proba)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Print evaluation metrics\n",
    "print(f'Accuracy: {accuracy:.2f}')\n",
    "print(f'Precision: {precision:.2f}')\n",
    "print(f'Recall: {recall:.2f}')\n",
    "print(f'F1-Score: {f1:.2f}')\n",
    "print(f'ROC-AUC: {roc_auc:.2f}')\n",
    "print(f'Confusion Matrix:\\n{conf_matrix}')\n",
    "\n",
    "# Fairness metrics\n",
    "for feature in ['sex', 'race', 'total_adult_crimes_bin']:\n",
    "    print(f\"\\nFairness metrics for {feature}:\")\n",
    "    disparate_impact = demographic_parity_ratio(y_true=y_test, y_pred=y_pred, sensitive_features=df_test[feature])\n",
    "    equalized_odds = equalized_odds_ratio(y_true=y_test, y_pred=y_pred, sensitive_features=df_test[feature])\n",
    "    tpr_diff = true_positive_rate_difference(y_true=y_test, y_pred=y_pred, sensitive_features=df_test[feature])\n",
    "    fpr_diff = false_positive_rate_difference(y_true=y_test, y_pred=y_pred, sensitive_features=df_test[feature])\n",
    "    selection_rate_diff = selection_rate_difference(y_true=y_test, y_pred=y_pred, sensitive_features=df_test[feature])\n",
    "    print(f\"Disparate Impact Ratio: {disparate_impact:.2f}\")\n",
    "    print(f\"Equalized Odds Ratio: {equalized_odds:.2f}\")\n",
    "    print(f\"True Positive Rate Difference: {tpr_diff:.2f}\")\n",
    "    print(f\"False Positive Rate Difference: {fpr_diff:.2f}\")\n",
    "    print(f\"Selection Rate Difference: {selection_rate_diff:.2f}\")\n",
    "\n",
    "# Disparate impact ratios by group for each sensitive feature\n",
    "def calculate_disparate_impact(y_true, y_pred, X_test, column):\n",
    "    disparate_impact_ratios = {}\n",
    "    overall_favorable_outcomes = y_pred.mean()\n",
    "    for value in X_test[column].unique():\n",
    "        mask = X_test[column] == value\n",
    "        favorable_outcomes = y_pred[mask].mean()\n",
    "        if overall_favorable_outcomes == 0:\n",
    "            disparate_impact_ratios[value] = np.nan\n",
    "        else:\n",
    "            disparate_impact_ratios[value] = favorable_outcomes / overall_favorable_outcomes\n",
    "    return disparate_impact_ratios\n",
    "\n",
    "for feature in ['sex', 'race', 'total_adult_crimes_bin']:\n",
    "    disparate_impact_by_group = calculate_disparate_impact(y_test, y_pred, df_test, feature)\n",
    "    print(f\"\\nDisparate Impact Ratios by {feature.capitalize()}:\")\n",
    "    for group, ratio in disparate_impact_by_group.items():\n",
    "        print(f\"{group}: {ratio:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "2ef7bf55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC: 0.65\n",
      "\n",
      "Fairness metrics for sex:\n",
      "Disparate Impact Ratio: 0.56\n",
      "Equalized Odds Ratio: 0.56\n",
      "True Positive Rate Difference: 0.18\n",
      "False Positive Rate Difference: 0.11\n",
      "Selection Rate Difference: 0.17\n",
      "\n",
      "Fairness metrics for race:\n",
      "Disparate Impact Ratio: 0.33\n",
      "Equalized Odds Ratio: 0.00\n",
      "True Positive Rate Difference: 0.67\n",
      "False Positive Rate Difference: 0.30\n",
      "Selection Rate Difference: 0.33\n",
      "\n",
      "Fairness metrics for total_adult_crimes_bin:\n",
      "Disparate Impact Ratio: 0.09\n",
      "Equalized Odds Ratio: 0.06\n",
      "True Positive Rate Difference: 0.81\n",
      "False Positive Rate Difference: 0.87\n",
      "Selection Rate Difference: 0.84\n",
      "\n",
      "Disparate Impact Ratios by Sex:\n",
      "Male: 1.10\n",
      "Female: 0.61\n",
      "\n",
      "Disparate Impact Ratios by Race:\n",
      "African-American: 1.29\n",
      "Asian: 0.48\n",
      "Caucasian: 0.68\n",
      "Other: 0.72\n",
      "Hispanic: 0.71\n",
      "Native American: 1.43\n",
      "\n",
      "Disparate Impact Ratios by Total_adult_crimes_bin:\n",
      "10+: 2.64\n",
      "3-4: 2.47\n",
      "<0: 0.36\n",
      "1-2: 0.62\n",
      "0: 0.23\n",
      "5-9: 2.29\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# Preprocess data function\n",
    "def preprocess_data(df):\n",
    "    df['dob'] = pd.to_datetime(df['dob'])\n",
    "    df['c_offense_date'] = pd.to_datetime(df['c_offense_date'])\n",
    "    df['c_arrest_date'] = pd.to_datetime(df['c_arrest_date'])\n",
    "    df['c_jail_in'] = pd.to_datetime(df['c_jail_in'])\n",
    "    df['unified_date'] = df['c_arrest_date'].combine_first(df['c_offense_date'])\n",
    "    df['age_birth'] = (pd.to_datetime('today') - df['dob']).dt.days // 365\n",
    "    df['age_at_unified_date'] = (df['unified_date'] - df['dob']).dt.days // 365\n",
    "    \n",
    "    avg_time_offense_arrest = (df['c_arrest_date'] - df['c_offense_date']).dt.days.mean()\n",
    "    avg_time_since_jail_in = (pd.to_datetime('today') - df['c_jail_in']).dt.days.mean()\n",
    "    avg_time_to_jail = (df['c_jail_in'] - df['unified_date']).dt.days.mean()\n",
    "\n",
    "    df['time_offense_arrest'] = (df['c_arrest_date'] - df['c_offense_date']).dt.days.fillna(avg_time_offense_arrest)\n",
    "    df['time_since_jail_in'] = (pd.to_datetime('today') - df['c_jail_in']).dt.days.fillna(avg_time_since_jail_in)\n",
    "    df['time_to_jail'] = (df['c_jail_in'] - df['unified_date']).dt.days.fillna(avg_time_to_jail)\n",
    "    \n",
    "    df['total_juv_crimes'] = df['juv_fel_count'] + df['juv_misd_count'] + df['juv_other_count']\n",
    "    df['total_adult_crimes'] = df['priors_count'] - df['total_juv_crimes']\n",
    "    df['c_charge_desc_freq'] = df['c_charge_desc'].map(df['c_charge_desc'].value_counts(normalize=True))\n",
    "\n",
    "    bins = [-np.inf, 0, 1, 3, 5, 10, np.inf]\n",
    "    labels = ['<0', '0', '1-2', '3-4', '5-9', '10+']\n",
    "    df['total_adult_crimes_bin'] = pd.cut(df['total_adult_crimes'], bins=bins, labels=labels)\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Load and preprocess data\n",
    "df = preprocess_data(df)\n",
    "\n",
    "# Split data into train and test sets\n",
    "df_train, df_test = train_test_split(df, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define features\n",
    "all_features = [\"sex\", \"race\", \"total_adult_crimes_bin\", \"c_charge_degree\", \"c_charge_desc_freq\", \"age_at_unified_date\", \"total_juv_crimes\", \"offense_month\", \"offense_day_of_week\", \"arrest_month\", \"arrest_day_of_week\"]\n",
    "numerical_features = [\"total_juv_crimes\", \"offense_month\", \"offense_day_of_week\", \"arrest_month\", \"arrest_day_of_week\", \"age_at_unified_date\", \"c_charge_desc_freq\"]\n",
    "categorical_features = [\"sex\", \"race\", \"total_adult_crimes_bin\", \"c_charge_degree\"]\n",
    "target = 'is_recid'\n",
    "\n",
    "# Define preprocessing pipelines\n",
    "numeric_transformer = Pipeline(steps=[('imputer', SimpleImputer(strategy='median')), ('scaler', StandardScaler())])\n",
    "categorical_transformer = Pipeline(steps=[('imputer', SimpleImputer(strategy='constant', fill_value='missing_value')), ('onehot', OneHotEncoder(handle_unknown='ignore'))])\n",
    "preprocessor = ColumnTransformer(transformers=[('num', numeric_transformer, numerical_features), ('cat', categorical_transformer, categorical_features)])\n",
    "\n",
    "# Compute sample weights\n",
    "def compute_sample_weights(df, sensitive_feature):\n",
    "    group_counts = df[sensitive_feature].value_counts()\n",
    "    total_count = len(df)\n",
    "    sample_weights = df[sensitive_feature].apply(lambda x: total_count / (len(group_counts) * group_counts[x]))\n",
    "    return sample_weights\n",
    "\n",
    "# Apply reweighing for the 'race' feature\n",
    "sample_weights = compute_sample_weights(df_train, 'race')\n",
    "\n",
    "# Define model parameters\n",
    "best_model_params = {'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 300, 'subsample': 0.8, 'random_state': 42}\n",
    "pipeline = Pipeline(steps=[('preprocessor', preprocessor), ('classifier', GradientBoostingClassifier(**best_model_params))])\n",
    "\n",
    "# Train the model with sample weights\n",
    "X_train = df_train[all_features]\n",
    "y_train = df_train[target]\n",
    "pipeline.fit(X_train, y_train, classifier__sample_weight=sample_weights)\n",
    "\n",
    "# Evaluate the model\n",
    "X_test = df_test[all_features]\n",
    "y_test = df_test[target]\n",
    "y_pred = pipeline.predict(X_test)\n",
    "roc_auc = roc_auc_score(y_test, y_pred)\n",
    "\n",
    "print(f'ROC-AUC: {roc_auc:.2f}')\n",
    "# Fairness metrics\n",
    "for feature in ['sex', 'race', 'total_adult_crimes_bin']:\n",
    "    print(f\"\\nFairness metrics for {feature}:\")\n",
    "    disparate_impact = demographic_parity_ratio(y_true=y_test, y_pred=y_pred, sensitive_features=df_test[feature])\n",
    "    equalized_odds = equalized_odds_ratio(y_true=y_test, y_pred=y_pred, sensitive_features=df_test[feature])\n",
    "    tpr_diff = true_positive_rate_difference(y_true=y_test, y_pred=y_pred, sensitive_features=df_test[feature])\n",
    "    fpr_diff = false_positive_rate_difference(y_true=y_test, y_pred=y_pred, sensitive_features=df_test[feature])\n",
    "    selection_rate_diff = selection_rate_difference(y_true=y_test, y_pred=y_pred, sensitive_features=df_test[feature])\n",
    "    print(f\"Disparate Impact Ratio: {disparate_impact:.2f}\")\n",
    "    print(f\"Equalized Odds Ratio: {equalized_odds:.2f}\")\n",
    "    print(f\"True Positive Rate Difference: {tpr_diff:.2f}\")\n",
    "    print(f\"False Positive Rate Difference: {fpr_diff:.2f}\")\n",
    "    print(f\"Selection Rate Difference: {selection_rate_diff:.2f}\")\n",
    "\n",
    "# Disparate impact ratios by group for each sensitive feature\n",
    "def calculate_disparate_impact(y_true, y_pred, X_test, column):\n",
    "    disparate_impact_ratios = {}\n",
    "    overall_favorable_outcomes = y_pred.mean()\n",
    "    for value in X_test[column].unique():\n",
    "        mask = X_test[column] == value\n",
    "        favorable_outcomes = y_pred[mask].mean()\n",
    "        if overall_favorable_outcomes == 0:\n",
    "            disparate_impact_ratios[value] = np.nan\n",
    "        else:\n",
    "            disparate_impact_ratios[value] = favorable_outcomes / overall_favorable_outcomes\n",
    "    return disparate_impact_ratios\n",
    "\n",
    "for feature in ['sex', 'race', 'total_adult_crimes_bin']:\n",
    "    disparate_impact_by_group = calculate_disparate_impact(y_test, y_pred, df_test, feature)\n",
    "    print(f\"\\nDisparate Impact Ratios by {feature.capitalize()}:\")\n",
    "    for group, ratio in disparate_impact_by_group.items():\n",
    "        print(f\"{group}: {ratio:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "05117423",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Serialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "9be73db7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6804188716159676"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Serialization\n",
    "TMP_DIR = ''\n",
    "\n",
    "# Serialize the column names from the X DataFrame into a file named columns.json\n",
    "# YOUR CODE HERE\n",
    "with open(os.path.join(TMP_DIR, \"columns.json\"), 'w') as fh:\n",
    "    json.dump(X_train.columns.tolist(), fh)\n",
    "\n",
    "# Pickle the dtypes of the columns from the X DataFrame into a file named dtypes.pickle\n",
    "# YOUR CODE HERE\n",
    "with open(os.path.join(TMP_DIR,'dtypes.pickle'), 'wb') as fh:\n",
    "    pickle.dump(X_train.dtypes, fh)\n",
    "    \n",
    "# Pickle the fitted pipeline into a file named pipeline.pickle\n",
    "# YOUR CODE HERE\n",
    "import joblib\n",
    "joblib.dump(pipeline, os.path.join(TMP_DIR,'pipeline.pickle'))\n",
    "\n",
    "# Baseline Scoring\n",
    "roc_auc_score(y_test, y_pred)\n",
    "#roc_auc_score(y_test, y_proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f636721",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Testing the App"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "a0d7d3dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response status code: 200\n",
      "Response content: {\n",
      "  \"id\": \"id_KVNBmR0jEq6hJBXN3L-rig\",\n",
      "  \"outcome\": false\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "url = \"http://127.0.0.1:5000/will_recidivate/\"\n",
    "\n",
    "data = {\n",
    "    \"id\": None,\n",
    "    \"name\": \"John Doe\",\n",
    "    \"sex\": \"Male\",\n",
    "    \"dob\": \"1990-01-01\",\n",
    "    \"race\": \"White\",\n",
    "    \"juv_fel_count\": 0,\n",
    "    \"juv_misd_count\": 1,\n",
    "    \"juv_other_count\": 0,\n",
    "    \"priors_count\": 2,\n",
    "    \"c_case_number\": \"case1234\",\n",
    "    \"c_charge_degree\": \"M\",\n",
    "    \"c_charge_desc\": \"Theft\",\n",
    "    \"c_offense_date\": \"2023-01-01\",\n",
    "    \"c_arrest_date\": \"2023-01-02\",\n",
    "    \"c_jail_in\": \"2023-01-03\"\n",
    "}\n",
    "\n",
    "headers = {'Content-Type': 'application/json'}\n",
    "r = requests.post(url, data=json.dumps(data), headers=headers)\n",
    "\n",
    "print(\"Response status code:\", r.status_code)\n",
    "print(\"Response content:\", r.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a1f0618",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "612a330d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My numpy version is:  2.1.0\n"
     ]
    }
   ],
   "source": [
    "#import pandas as pd\n",
    "#print(\"My numpy version is: \", pd.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f9859009",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recidivism outcome updated successfully for ID: a1b2c345\n",
      "True outcome: True\n",
      "Predicted outcome: False\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "# Define the URL of your Flask application\n",
    "url = 'http://127.0.0.1:5000/recidivism_result/'  # Update with your actual URL\n",
    "\n",
    "# Define the observation data\n",
    "data = {\n",
    "    \"id\": \"a1b2c345\",\n",
    "    \"outcome\": True\n",
    "}\n",
    "\n",
    "headers = {'Content-Type': 'application/json'}\n",
    "response = requests.post(url, data=json.dumps(data), headers=headers)\n",
    "\n",
    "# Check the response status code\n",
    "if response.status_code == 200:\n",
    "    try:\n",
    "        result = response.json()\n",
    "        observation_id = result.get('id')  # Correct key\n",
    "        outcome = result.get('outcome')  # Correct key\n",
    "        predicted_outcome = result.get('predicted_outcome')  # Correct key\n",
    "        if observation_id is not None and outcome is not None:\n",
    "            print(\"Recidivism outcome updated successfully for ID:\", observation_id)\n",
    "            print(\"True outcome:\", outcome)\n",
    "            print(\"Predicted outcome:\", predicted_outcome)\n",
    "        else:\n",
    "            print(\"Observation ID or outcome not found in the response\")\n",
    "    except ValueError:\n",
    "        print(\"Failed to parse JSON response\")\n",
    "else:\n",
    "    print(\"Failed to update recidivism outcome:\", response.text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "1ea649f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response status code: 200\n",
      "Response content: {\n",
      "  \"error\": \"Observation ID: \\\"a1b2c34567\\\" already exists\",\n",
      "  \"id\": \"a1b2c34567\",\n",
      "  \"outcome\": false\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "url = \"https://capstone-production-ddd2.up.railway.app/will_recidivate/\"\n",
    "\n",
    "data = {\n",
    "    \"id\": \"a1b2c34567\",\n",
    "    \"name\": \"John Doe\",\n",
    "    \"sex\": \"Male\",\n",
    "    \"dob\": \"1990-01-01\",\n",
    "    \"race\": \"White\",\n",
    "    \"juv_fel_count\": 0,\n",
    "    \"juv_misd_count\": 1,\n",
    "    \"juv_other_count\": 0,\n",
    "    \"priors_count\": 2,\n",
    "    \"c_case_number\": \"case1234\",\n",
    "    \"c_charge_degree\": \"M\",\n",
    "    \"c_charge_desc\": \"Theft\",\n",
    "    \"c_offense_date\": \"2023-01-01\",\n",
    "    \"c_arrest_date\": \"2023-01-02\",\n",
    "    \"c_jail_in\": \"2023-01-03\"\n",
    "}\n",
    "\n",
    "\n",
    "headers = {'Content-Type': 'application/json'}\n",
    "r = requests.post(url, data=json.dumps(data), headers=headers)\n",
    "\n",
    "print(\"Response status code:\", r.status_code)\n",
    "print(\"Response content:\", r.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e11ebf5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "93de527e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status Code: 200\n",
      "{'error': 'Observation ID: \"a1b2c3\" already exists', 'id': 'a1b2c3', 'outcome': False}\n",
      "Status Code: 200\n",
      "{'id': 'a1b2c3456', 'outcome': True, 'predicted_outcome': False}\n",
      "Status Code: 200\n",
      "[{'id': 1, 'observation': '{\"id\": \"a1b2c345\", \"name\": \"6cea57c2fb6cbc2a40411135005760f241fffc3e5e67ab99882726431037f908\", \"sex\": \"Male\", \"dob\": \"1990-01-01\", \"race\": \"White\", \"juv_fel_count\": 0, \"juv_misd_count\": 1, \"juv_other_count\": 0, \"priors_count\": 2, \"c_case_number\": \"case1234\", \"c_charge_degree\": \"M\", \"c_charge_desc\": \"Theft\", \"c_offense_date\": \"2023-01-01\", \"c_arrest_date\": \"2023-01-02\", \"c_jail_in\": \"2023-01-03\"}', 'observation_id': 'a1b2c345', 'outcome': False, 'predicted_outcome': False}, {'id': 2, 'observation': '{\"id\": \"a1b2c3\", \"name\": \"6cea57c2fb6cbc2a40411135005760f241fffc3e5e67ab99882726431037f908\", \"sex\": \"Male\", \"dob\": \"1990-01-01\", \"race\": \"Caucasian\", \"juv_fel_count\": 2, \"juv_misd_count\": 1, \"juv_other_count\": 0, \"priors_count\": 5, \"c_case_number\": \"A123456\", \"c_charge_degree\": \"F\", \"c_charge_desc\": \"Burglary\", \"c_offense_date\": \"2022-01-01\", \"c_arrest_date\": \"2022-01-02\", \"c_jail_in\": \"2022-01-03\"}', 'observation_id': 'a1b2c3', 'outcome': True, 'predicted_outcome': False}, {'id': 5, 'observation': '{\"id\": \"a1b2c3456\", \"name\": \"6cea57c2fb6cbc2a40411135005760f241fffc3e5e67ab99882726431037f908\", \"sex\": \"Male\", \"dob\": \"1990-01-01\", \"race\": \"White\", \"juv_fel_count\": 0, \"juv_misd_count\": 1, \"juv_other_count\": 0, \"priors_count\": 2, \"c_case_number\": \"case1234\", \"c_charge_degree\": \"M\", \"c_charge_desc\": \"Theft\", \"c_offense_date\": \"2023-01-01\", \"c_arrest_date\": \"2023-01-02\", \"c_jail_in\": \"2023-01-03\"}', 'observation_id': 'a1b2c3456', 'outcome': True, 'predicted_outcome': False}]\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "def test_will_recidivate():\n",
    "    url = \"https://capstone-production-811f.up.railway.app/will_recidivate/\"\n",
    "    data = {\n",
    "        \"id\": \"a1b2c3\",\n",
    "        \"name\": \"John Doe\",\n",
    "        \"sex\": \"Male\",\n",
    "        \"dob\": \"1990-01-01\",\n",
    "        \"race\": \"Caucasian\",\n",
    "        \"juv_fel_count\": 2,\n",
    "        \"juv_misd_count\": 1,\n",
    "        \"juv_other_count\": 0,\n",
    "        \"priors_count\": 5,\n",
    "        \"c_case_number\": \"A123456\",\n",
    "        \"c_charge_degree\": \"F\",\n",
    "        \"c_charge_desc\": \"Burglary\",\n",
    "        \"c_offense_date\": \"2022-01-01\",\n",
    "        \"c_arrest_date\": \"2022-01-02\",\n",
    "        \"c_jail_in\": \"2022-01-03\"\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        response = requests.post(url, json=data)\n",
    "        response.raise_for_status()  # Raise an error for bad status codes\n",
    "        print(f\"Status Code: {response.status_code}\")\n",
    "        print(response.json())\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        if response is not None:\n",
    "            print(f\"Status Code: {response.status_code}\")\n",
    "            print(response.text)\n",
    "\n",
    "def test_recidivism_result():\n",
    "    url = \"https://capstone-production-811f.up.railway.app/recidivism_result/\"\n",
    "    data = {\n",
    "        \"id\": \"a1b2c3456\",\n",
    "        \"outcome\": True\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        response = requests.post(url, json=data)\n",
    "        response.raise_for_status()  # Raise an error for bad status codes\n",
    "        print(f\"Status Code: {response.status_code}\")\n",
    "        print(response.json())\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        if response is not None:\n",
    "            print(f\"Status Code: {response.status_code}\")\n",
    "            print(response.text)\n",
    "\n",
    "def list_db_contents():\n",
    "    url = \"https://capstone-production-811f.up.railway.app/list-db-contents\"\n",
    "\n",
    "    try:\n",
    "        response = requests.get(url)\n",
    "        response.raise_for_status()  # Raise an error for bad status codes\n",
    "        print(f\"Status Code: {response.status_code}\")\n",
    "        print(response.json())\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        if response is not None:\n",
    "            print(f\"Status Code: {response.status_code}\")\n",
    "            print(response.text)\n",
    "\n",
    "# Run the tests\n",
    "test_will_recidivate()\n",
    "test_recidivism_result()\n",
    "list_db_contents()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0d9e4253",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unterminated string literal (detected at line 1) (710772726.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[5], line 1\u001b[0;36m\u001b[0m\n\u001b[0;31m    curl -X POST https://capstone-production-d66f.up.railway.app/will_recidivate -d '{\"id\": \"123456abc\",\u001b[0m\n\u001b[0m                                                                                    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unterminated string literal (detected at line 1)\n"
     ]
    }
   ],
   "source": [
    "curl -X POST https://capstone-production-fe80.up.railway.app/will_recidivate/ -d '{\"id\": \"test123\",\n",
    "        \"name\": \"John Doe\",\n",
    "        \"sex\": \"Male\",\n",
    "        \"dob\": \"1990-01-01\",\n",
    "        \"race\": \"Caucasian\",\n",
    "        \"juv_fel_count\": 2,\n",
    "        \"juv_misd_count\": 1,\n",
    "        \"juv_other_count\": 0,\n",
    "        \"priors_count\": 5,\n",
    "        \"c_case_number\": \"A123456\",\n",
    "        \"c_charge_degree\": \"F\",\n",
    "        \"c_charge_desc\": \"Burglary\",\n",
    "        \"c_offense_date\": \"2022-01-01\",\n",
    "        \"c_arrest_date\": \"2022-01-02\",\n",
    "        \"c_jail_in\": \"2022-01-03\"}' -H \"Content-Type:application/json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8180f50f",
   "metadata": {},
   "outputs": [],
   "source": [
    "curl -X POST https://capstone-production-d66f.up.railway.app/recidivism_result -d '{\n",
    "         \"id\": \"123456abc\",\n",
    "        \"outcome\": true\n",
    "         }' -H \"Content-Type:application/json\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
